<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Natural Language Processing for Research: Large Language Models</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="manifest" href="../site.webmanifest"><link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../06-llms.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Natural Language Processing for Research
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Natural Language Processing for Research
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="../aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Natural Language Processing for Research
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 64%" class="percentage">
    64%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 64%" aria-valuenow="64" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../06-llms.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction to Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-text-preprocessing.html">2. Introduction to Text Preprocessing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-text-analysis.html">3. Text Analysis</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-word-embedding.html">4. Word Embedding</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-transformers.html">5. Transformers for Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        6. Large Language Models
        </span>
      </button>
    </div><!--/div.accordion-header-->
        
    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#introduction-to-llms">6.1. Introduction to LLMs</a></li>
<li><a href="#bert">6.2. BERT</a></li>
<li><a href="#gpt">6.3. GPT</a></li>
<li><a href="#open-source-llms">6.4. Open-Source LLMs:</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-domain-specific-llms.html">7. Domain-Specific LLMs</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-conclusion-final-project.html">8. Wrap-up and Final Project</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-transformers.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-transformers.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Transformers for
        </a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html" rel="next">
          Next: Domain-Specific LLMs... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Large Language Models</h1>
        <p>Last updated on 2024-05-12 |
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/06-llms.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are the main features of large language models?</li>
<li>How is BERT different from GPT models?</li>
<li>How can I use open-source LLMs, such as LLM examples in huggingface,
for research tasks?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Be able to explain the structure of large language models and their
main components</li>
<li>Identify differences between BERT and GPT.</li>
<li>Be able to use open-source LLMs, such as huggingface, for text
summarization, classification, and generation.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section id="introduction-to-llms"><h2 class="section-heading">6.1. Introduction to LLMs<a class="anchor" aria-label="anchor" href="#introduction-to-llms"></a>
</h2>
<hr class="half-width"><p>Large Language Models (LLMs) have become a cornerstone of modern
natural language processing (NLP). Since the introduction of the
transformer architecture in 2017, LLMs have leveraged this design to
achieve remarkable language understanding and generation capabilities.
In the previous episode, we discussed the transformer architecture,
which is integral to all LLMs, utilizing its encoder and decoder
components to process language.</p>
<p>LLMs have several key features.</p>
<figure><img src="../fig/llms_1.png" class="figure mx-auto d-block"></figure><div id="challenge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge"></a>
</h3>
<div class="callout-content">
<p>Fill in the above feature placeholders. Discuss what are these key
components. Explain the key features in detail and compare your thoughts
with the other group members:</p>
<ol style="list-style-type: decimal"><li><p>Transformer Architecture: A neural network design that uses
self-attention mechanisms to weigh the influence of different parts of
the input data.</p></li>
<li><p>Pre-training: involves teaching LLMs to anticipate words in
sentences, using either bi-directional or uni-directional approaches,
(based on the LLM type), without the need for understanding or
experience.</p></li>
<li><hr></li>
<li><hr></li>
<li><hr></li>
<li><hr></li>
</ol></div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<figure><img src="../fig/llms_4.png" class="figure mx-auto d-block"></figure><ol style="list-style-type: decimal"><li><p>Transformer Architecture: A neural network design that uses
self-attention mechanisms to weigh the influence of different parts of
the input data.</p></li>
<li><p>Pre-training: involves teaching LLMs to anticipate words in
sentences, using either bi-directional or uni-directional approaches,
(based on the LLM type), without the need for understanding or
experience.</p></li>
<li><p>Word/Token Embedding: The process of converting words or phrases
into numerical form (vectors) that computers can understand.</p></li>
</ol><p><strong>RECALL</strong> embedding?</p>
<figure><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/06a4c996-cfe4-414e-b91c-9048c1006fc6" alt="image" class="figure mx-auto d-block"><div class="figcaption">image</div>
</figure><p><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/6e7a5d15-94a4-4522-910f-3ad67dd2ee69" alt="image" class="figure"><a href="https://www.shanelynn.ie/get-busy-with-word-embeddings-introduction/" class="external-link">source</a></p>
<ol start="4" style="list-style-type: decimal"><li><p>Context Window: The range of words the model considers for
predicting the next word or understanding the current word within a
sentence.</p></li>
<li><p>Parameters: The aspects of the model that are learned from
training data and determine the model’s behavior.</p></li>
<li><p>Transfer Learning: The process LLMs use to apply their prior
knowledge to new tasks.</p></li>
</ol><p>Thus, the completed graph will be:</p>
</div>
</div>
</div>
</div>
<p>We can categorize LLMs based on the transformer architecture. Let’s
have another look into the transformer architecture, this time we
categorize them based on the two main components: <strong>Encoder and
Decoder</strong>. LLMs can be designed to handle different tasks based
on their underlying transformer blocks and whether they have
encoder-only, decoder-only, or encoder-decoder layers.</p>
<figure><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/db7f7677-67eb-475d-bb3e-3b703b2fbb0f" alt="image" class="figure mx-auto d-block"><div class="figcaption">image</div>
</figure><div id="challenge-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-1" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-1"></a>
</h3>
<div class="callout-content">
<p>How do you think we should connect each one of the following
transformers to the correct color?</p>
<figure><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/7b5bd803-c075-4b66-9d8e-b989172f50d8" alt="image" class="figure mx-auto d-block"><div class="figcaption">image</div>
</figure></div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<figure><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/9d4afc99-d8f4-4a17-9af9-5fab4fac5dfd" alt="image" class="figure mx-auto d-block"><div class="figcaption">image</div>
</figure></div>
</div>
</div>
</div>
<p>• Encoders are used for understanding tasks like sentence
classification.</p>
<p>• Decoders excel in generative tasks like text generation.</p>
<p>• The combination of encoders and decoders in transformers allows
them to be versatile and perform a variety of tasks, from translation to
summarization, depending on the specific requirements of the task at
hand.</p>
<div id="encoder-vs.-decoder-andor-bert-vs.-gpt" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="encoder-vs.-decoder-andor-bert-vs.-gpt" class="callout-inner">
<h3 class="callout-title">Encoder Vs. Decoder and/or BERT Vs. GPT<a class="anchor" aria-label="anchor" href="#encoder-vs.-decoder-andor-bert-vs.-gpt"></a>
</h3>
<div class="callout-content">
<p>We will see models like BERT use encoders for bidirectional
understanding, and models like GPT use decoders for generating coherent
text, making them suitable for chatbots or virtual assistants.</p>
</div>
</div>
</div>
<div id="discussion" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="discussion" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion"></a>
</h3>
<div class="callout-content">
<p>Teamwork: Think of some examples of traditional NLP models, such as
n-gram models, hidden Markov models, LSTMs, and RNNs. How do large
language models differ from them in terms of architecture, data, and
performance?</p>
<p>A: Traditional NLP models, such as n-gram models, hidden Markov
models (HMMs), Long Short-Term Memory Networks (LSTMs), and Recurrent
Neural Networks (RNNs), differ significantly from the recent LLMs.
N-gram models predict the next item in a sequence based on the previous
‘n-1’ items without any deep understanding of context. HMMs are
statistical models that output probabilities of sequences and are often
used for tasks like part-of-speech tagging. LSTMs and RNNs are types of
neural networks that can process sequences of data and are capable of
learning order dependence in sequence prediction.</p>
<p>Compared to these traditional models, LLMs have several key
differences: - <strong>Architecture</strong>: Novel LLMs use transformer
architectures, which are more advanced than the simple recurrent units
of RNNs or the gated units of LSTMs. Transformers use self-attention to
weigh the influence of different parts of the input data, which is more
effective for understanding context. - <strong>Data</strong>: Novel LLMs
are trained on massive datasets, often sourced from the internet, which
allows them to learn a wide variety of language patterns, common
knowledge, and even reasoning abilities. Traditional models typically
use smaller, more curated datasets. - <strong>Performance</strong>:
Novel LLMs generally outperform traditional models in a wide range of
language tasks due to their ability to understand and generate
human-like text. They can capture subtleties and complexities of
language that simpler models cannot, leading to more accurate and
coherent outputs.</p>
</div>
</div>
</div>
</section><section id="bert"><h2 class="section-heading">6.2. BERT<a class="anchor" aria-label="anchor" href="#bert"></a>
</h2>
<hr class="half-width"><p>Bidirectional Encoder Representations from Transformers (BERT) is an
LLM that uses an encoder-only architecture from transformers. It is
designed to understand the context of a word based on all of its
surroundings (bidirectional context). Let’s guess the missing words in
the text below to comprehend the workings of BERT:</p>
<div id="challenge-2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-2" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-2"></a>
</h3>
<div class="callout-content">
<p>Complete the following paragraph:</p>
<p>“BERT is a revolutionary language model that uses an ______ (encoder)
to process words in a sentence. Unlike traditional models, it predicts
words based on the ______ rather than in sequence. Its training involves
______, where words are intentionally hidden, or ______, and the model
learns to predict them. This results in rich ______ that capture the
nuanced meanings of words.”</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">Show me the solution</h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>“BERT is a revolutionary language model that uses an
<strong>encoder</strong> to process words in a sentence. Unlike
traditional models, it predicts words based on the
<strong>context</strong> rather than in sequence. Its training involves
<strong>self-supervised learning</strong>, where words are intentionally
hidden, or <strong>‘masked’</strong>, and the model learns to predict
them. This results in rich <strong>embeddings</strong> that capture the
nuanced meanings of words.”</p>
</div>
</div>
</div>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: MLM &amp; NSP</h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<p>Pre-training of language models involves a process where models like
BERT and GPT learn to predict words in sentences without specific task
training. This is achieved through methods like the Masked Language
Model (MLM) for bi-directional models, which predict masked words using
surrounding context. MLM in BERT predicts missing words in a sentence by
masking them during training.</p>
<p>For Next Sentence Prediction (NSP) BERT learns to predict if two
sentences logically follow each other.</p>
</div>
</div>
</div>
</div>
</section><section id="gpt"><h2 class="section-heading">6.3. GPT<a class="anchor" aria-label="anchor" href="#gpt"></a>
</h2>
<hr class="half-width"><p>Generative Pretrained Transformer (GPT) models, on the other hand,
use a decoder-only architecture. They excel at generating coherent and
contextually relevant text. Check the following table that summarizes
three different LLMs. The middle column misses some information about
GPT models. With the help of your teammates complete the table and
explain the differences in the end.</p>
<div id="challenge-3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-3" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-3"></a>
</h3>
<div class="callout-content">
<p>Write in the gray boxes with the correct explanations.</p>
<p><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/c1bd86ec-2b48-4201-bc7f-db63d73b0df9" alt="image" class="figure"><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/e50f0111-2956-418d-8dba-612e1942ddfd" alt="image" class="figure"><a href="https://medium.com/@reyhaneh.esmailbeigi/bert-gpt-and-bart-a-short-comparison-5d6a57175fca" class="external-link">source</a></p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4">Show me the solution</h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/c01d8b7f-b237-499b-b169-d40c785e30d0" alt="image" class="figure"><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/1153ca29-aafd-4de6-8013-525b21ded916" alt="image" class="figure"><a href="https://medium.com/@reyhaneh.esmailbeigi/bert-gpt-and-bart-a-short-comparison-5d6a57175fca" class="external-link">source</a></p>
</div>
</div>
</div>
</div>
<div id="discussion-1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="discussion-1" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion-1"></a>
</h3>
<div class="callout-content">
<p>Teamwork: From what you learned above how can you explain the
differences between the three LLM types? Discuss in groups and share
your answers.</p>
<p>A: <em>We can see it as the processes of trying to understand a
conversation (BERT), versus trying to decide what to say next in the
conversation (GPT). BERT is like someone who listens to the entire
conversation before and after a word to really understand its
meaning.</em></p>
<p><em>For example, in the sentence “I ate an apple,” BERT would look at
both “I ate an” and “apple” to figure out what <strong>“an”</strong>
refers to. It’s trained by playing a game of <strong>‘guess the missing
word,’</strong> where some words are hidden <strong>(masked)</strong>
and it has to use the context to fill in the blanks.</em></p>
<p><em>GPT, on the other hand, is like a storyteller who only needs to
know what was said before to continue the tale. It would take “I ate an”
and <strong>predict that the next word</strong> might be “apple.” It
learns by <strong>reading a lot of text</strong> and practicing how to
predict the next word in a sentence.</em></p>
<p><em>Both are smart in their own ways, but they’re used for different
types of language tasks. BERT is great for understanding the
<strong>context of words</strong>, while GPT is excellent at
<strong>generating new text</strong> based on what it’s seen before. The
following schematics demonstrate their performing differences:</em></p>
<p><img src="https://github.com/qcif-training/intro_nlp_lmm_v1.0/assets/45458783/114d8549-dede-4976-8e69-167cfe33879f" alt="image" class="figure"><a href="https://medium.com/@reyhaneh.esmailbeigi/bert-gpt-and-bart-a-short-comparison-5d6a57175fca" class="external-link">source</a></p>
</div>
</div>
</div>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>How LLMs can be Compared? What is HELM?</h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler2" aria-labelledby="headingSpoiler2">
<div class="accordion-body">
<p>Models are often benchmarked using standardized datasets and metrics.
The Holistic Evaluation of Language Models (HELM) by Stanford provides a
comprehensive framework for evaluating LLMs across multiple
dimensions.</p>
<p><img src="../fig/llms_9.png" class="figure"><a href="https://crfm.stanford.edu/helm/lite/latest/" class="external-link">source</a></p>
<p>GPT-4 models are outperforming other LLM models in terms of
accuracy.</p>
</div>
</div>
</div>
</div>
<div id="discussion-2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="discussion-2" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion-2"></a>
</h3>
<div class="callout-content">
<p>What are some examples of LLMs, and how are they trained and used for
research tasks? Consider some of the main features and characteristics
of LLMs, such as transformer architecture, self-attention mechanism,
pre-training and fine-tuning, and embedding capabilities. How do these
features enable LLMs to perform various NLP tasks, such as text
classification, text generation, or question answering?</p>
</div>
</div>
</div>
<div id="challenge-4" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-4" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-4"></a>
</h3>
<div class="callout-content">
<p>How can we compare different LLMs? Are there any benchmarks?</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5">Show me the solution</h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" data-bs-parent="#accordionSolution5" aria-labelledby="headingSolution5">
<div class="accordion-body">
<p>A: Comparing Performance (Benchmarking): 1. Performance can be
compared based on the model’s architecture, computational efficiency,
and suitability for specific tasks. 2. Benchmarks and leaderboards (such
as HELM) can provide insights into how different models perform on
standardized datasets. 3. Community feedback and use-case studies can
also inform the practical effectiveness of different LLMs.</p>
</div>
</div>
</div>
</div>
</section><section id="open-source-llms"><h2 class="section-heading">6.4. Open-Source LLMs:<a class="anchor" aria-label="anchor" href="#open-source-llms"></a>
</h2>
<hr class="half-width"><p>It is very important for researchers to openly have access to capable
LLMs for their studies. Fortunately, some companies are supporting
open-source LLMs. The BLOOM model, developed by the BigScience Workshop
in collaboration with Hugging Face and other organizations, was released
on July 6, 2022. It offers a wide range of model sizes, from 1.1 billion
to 176 billion parameters, and is licensed under the open RAIL-M v1.
BLOOM is known for its instruct models, coding capabilities,
customization finetuning, and being open source. It is more openly
accessible and benefits from a large community and extensive
support.</p>
<p>On the other hand, the LLaMA model, developed by Meta AI, was
released on February 24, 2023. It is available in four sizes: 7 billion,
13 billion, 33 billion, and 65 billion parameters. The license for LLaMA
is restricted to noncommercial use, and access is primarily for
researchers. Despite its smaller size, LLaMA is parameter-efficient and
has outperformed GPT-3 on many benchmarks. However, its accessibility is
more gated compared to BLOOM, and community support is limited to
approved researchers.</p>
<p>Now let’s summarize what we learned here in the following table:</p>
<figure><img src="../fig/llms_10.png" class="figure mx-auto d-block"></figure><p>Hugging Face provides several different LLMs. Now we want to see how
we can use an open-source model. using the Hugging Face datasets library
and an open-source Large Language Model (LLM). We will go through the
process of setting up the environment, installing necessary libraries,
loading a dataset, and then using an LLM to process the data. We will
start with setting up the environment.</p>
<div id="heads-up" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="heads-up" class="callout-inner">
<h3 class="callout-title">Heads up<a class="anchor" aria-label="anchor" href="#heads-up"></a>
</h3>
<div class="callout-content">
<p>Before we begin, ensure that you have Python installed on your
system. Python 3.6 or later is recommended. You can download Python from
the official Python website.</p>
</div>
</div>
</div>
<p>Next, we will install the necessary libraries through the terminal or
command prompt:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>pip install datasets transformers</span></code></pre>
</div>
<p>We use the <strong>squad dataset</strong> here, which is a
question-answering dataset Question-answering is one of main goals of
utilizing LLMs for research projects. When you run this script, the
expected output should be the answer to the question based on the
provided context. Here is how to load it:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Load the SQuAD dataset</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>squad_dataset <span class="op">=</span> load_dataset(<span class="st">'squad'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co"># Print the first example in the training set</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="bu">print</span>(squad_dataset[<span class="st">'train'</span>][<span class="dv">0</span>])</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span></code></pre>
</div>
<p>Now, we can load a pre-trained model from Hugging Face. For this
example, let’s use the bert-base-uncased model, which is different from
BLOOM and is suitable for question-answering tasks:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForQuestionAnswering, AutoTokenizer</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Load the tokenizer and model</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>model <span class="op">=</span> AutoModelForQuestionAnswering.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span></code></pre>
</div>
<p>We need to define the question and context here:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>question <span class="op">=</span> <span class="st">"What is the name of the university in Paris that was founded in 1257?"</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"The University of Paris, founded in 1257, is often referred to as the Sorbonne after the college created by Robert de Sorbon. It is one of the world's oldest universities."</span></span></code></pre>
</div>
<p>Recall to be able to feed data into the model, we should already
tokenize our data. Once we have our data tokenized, we can use the model
to make predictions. Here is how to tokenize the first example:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># Tokenize the first example</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>Inputs <span class="op">=</span> tokenizer(squad_dataset[<span class="st">'train'</span>][<span class="dv">0</span>][<span class="st">'question'</span>], squad_dataset[<span class="st">'train'</span>][<span class="dv">0</span>][<span class="st">'context'</span>], return_tensors<span class="op">=</span><span class="st">'pt'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co"># Get model predictions</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span></code></pre>
</div>
<p>Note that the model outputs are raw <strong>logits</strong>. We need
to convert these into an answer by selecting the tokens with the highest
start and end scores:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># Find the tokens with the highest `start` and `end` scores</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>answer_start <span class="op">=</span> torch.argmax(outputs.start_logits)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>answer_end <span class="op">=</span> torch.argmax(outputs.end_logits) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co"># Convert tokens to the answer string</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>answer <span class="op">=</span> tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens (inputs[<span class="st">'input_ids'</span>][<span class="dv">0</span>][answer_start:answer_end]))</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="bu">print</span>(answer)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span></code></pre>
</div>
<p>This will print the answer to the question based on the context
provided in the dataset. In this case, the output would be:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>Output: the sorbonne</span></code></pre>
</div>
<p>This output indicates that the model has correctly identified “the
Sorbonne” as the name of the university in Paris founded in 1257, based
on the context given. Remember, the actual output may vary slightly
depending on the model version and the specific weights used at the time
of inference.</p>
<div id="discussion-3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="discussion-3" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion-3"></a>
</h3>
<div class="callout-content">
<p>Teamwork: What are the challenges and implications of LLMs, such as
scalability, generalization, and social impact? What does it mean when
an LLM hallucinates?</p>
</div>
</div>
</div>
<div id="challenge-5" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-5" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-5"></a>
</h3>
<div class="callout-content">
<p>Use the OpenAI library to access and use an open-source LLM for text
summarization. You can use the following code to load the OpenAI library
and the pre-trained model and tokenizer for text summarization:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="im">import</span> openai</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">"sk-&lt;your_api_key&gt;"</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>text_summarizer <span class="op">=</span> openai.Completion.create(engine<span class="op">=</span><span class="st">"davinci"</span>, task<span class="op">=</span><span class="st">"summarize"</span>)</span></code></pre>
</div>
<p>Use the text_summarizer to summarize the following text.</p>
</div>
</div>
</div>
<div id="accordionSpoiler3" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler3" aria-expanded="false" aria-controls="collapseSpoiler3">
  <h3 class="accordion-header" id="headingSpoiler3">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Text</h3>
</button>
<div id="collapseSpoiler3" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler3" aria-labelledby="headingSpoiler3">
<div class="accordion-body">
<p>“Perovskite nanocrystals are a class of semiconductor nanocrystals,
which exhibit unique characteristics that separate them from traditional
quantum dots. Perovskite nanocrystals have an ABX3 composition where A =
cesium, methylammonium (MA), or formamidinium (FA); B = lead or tin; and
X = chloride, bromide, or iodide. Their unique qualities largely involve
their unusual band structure which renders these materials effectively
defect-tolerant or able to emit brightly without surface passivation.
This is in contrast to other quantum dots such as CdSe which must be
passivated with an epitaxially matched shell to be bright emitters. In
addition to this, lead-halide perovskite nanocrystals remain bright
emitters when the size of the nanocrystal imposes only weak quantum
confinement. This enables the production of nanocrystals that exhibit
narrow emission linewidths regardless of their polydispersity. The
combination of these attributes and their easy-to-perform synthesis has
resulted in numerous articles demonstrating the use of perovskite
nanocrystals as both classical and quantum light sources with
considerable commercial interest. Perovskite nanocrystals have been
applied to numerous other optoelectronic applications such as
light-emitting diodes, lasers, visible communication, scintillators,
solar cells, and photodetectors. The first report of perovskite
nanocrystals was published in 2014 by Protesescu et al., who synthesized
cesium lead halide nanocrystals using a hot-injection method. They
showed that the nanocrystals can emit brightly when excited by
ultraviolet or blue light, and their colors are tunable across the
entire visible spectrum by changing the halide from chloride (UV/blue)
to bromide (green) and iodide (red). They also demonstrated that the
nanocrystals can be incorporated into thin films and show high
photoluminescence quantum yields (PLQYs) of up to 90%. Since then, many
other synthetic methods have been developed to produce perovskite
nanocrystals with different shapes, sizes, compositions, and surface
ligands. Some of the common methods include ligand-assisted
reprecipitation, antisolvent precipitation, solvothermal synthesis,
microwave-assisted synthesis, and microfluidic synthesis. Perovskite
nanocrystals can be classified into different types based on their
structure, dimensionality, and composition. The most common type is the
three-dimensional (3D) perovskite nanocrystals, which have a cubic or
orthorhombic crystal structure and a band gap that depends on the halide
content. The 3D perovskite nanocrystals can be further divided into pure
halide perovskites (such as CsPbX3) and mixed halide perovskites (such
as CsPb(Br/I)3), which can exhibit color tuning, anion exchange, and
halide segregation phenomena. Another type is the two-dimensional (2D)
perovskite nanocrystals, which have a layered structure with organic
cations sandwiched between inorganic perovskite layers. The 2D
perovskite nanocrystals have a quantum well-like band structure and a
band gap that depends on the thickness of the perovskite layers. The 2D
perovskite nanocrystals can also be mixed with 3D perovskite
nanocrystals to form quasi-2D perovskite nanocrystals, which can improve
the stability and emission efficiency of the nanocrystals. A third type
is the metal-free perovskite nanocrystals, which replace the metal
cations (such as Pb or Sn) with other elements (such as Bi or Sb). The
metal-free perovskite nanocrystals have a lower toxicity and higher
stability than the metal-based perovskite nanocrystals, but they also
have a lower PLQY and a broader emission linewidth. The development of
perovskite nanocrystals in the past few years has been remarkable, with
significant advances in synthesis, characterization, and application.
However, there are still some challenges and opportunities for further
improvement. One of the major challenges is the stability of perovskite
nanocrystals, which are sensitive to moisture, oxygen, heat, light, and
electric fields. These factors can cause degradation, phase transition,
and non-radiative recombination of the nanocrystals, resulting in
reduced emission intensity and color stability. Several strategies have
been proposed to enhance the stability of perovskite nanocrystals, such
as surface passivation, encapsulation, doping, alloying, and embedding
in matrices. Another challenge is the toxicity of perovskite
nanocrystals, which are mainly composed of lead, a heavy metal that can
cause environmental and health hazards. Therefore, there is a need to
develop lead-free or low-lead perovskite nanocrystals that can maintain
the high performance and tunability of the lead-based ones. Some of the
promising candidates include tin-based, bismuth-based, and
antimony-based perovskite nanocrystals. A third challenge is the
scalability and integration of perovskite nanocrystals, which are
essential for practical applications. There is a need to develop
cost-effective and large-scale synthesis methods that can produce
high-quality and uniform perovskite nanocrystals. Moreover, there is a
need to develop efficient and reliable fabrication techniques that can
integrate perovskite nanocrystals into various devices and platforms. In
conclusion, perovskite nanocrystals are a fascinating class of
nanomaterials that have shown remarkable potential for various photonic
applications. They have unique properties such as defect tolerance, high
quantum yield, fast radiative decay, and narrow emission linewidth in
weak confinement, which make them ideal candidates for light emission
devices. They also have a wide color tunability from ultraviolet to
near-infrared regions, which makes them suitable for various
wavelength-dependent applications. However, there are still some
challenges that need to be overcome, such as stability, toxicity,
scalability, and integration. Therefore, further research and
development are needed to address these issues and to explore new
opportunities for perovskite nanocrystals in the field of
nanophotonics.</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6">Show me the solution</h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" data-bs-parent="#accordionSolution6" aria-labelledby="headingSolution6">
<div class="accordion-body">
<p>Print the summarized text.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> openai</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">"sk-&lt;your_api_key&gt;"</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>text_summarizer <span class="op">=</span> openai.Completion.create(engine<span class="op">=</span><span class="st">"davinci"</span>, task<span class="op">=</span><span class="st">"summarize"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>text <span class="op">=</span> <span class="st">" Perovskite nanocrystals are a class of semiconductor …"</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>summary <span class="op">=</span> text_summarizer(text)[<span class="st">'choices'</span>][<span class="dv">0</span>][<span class="st">'text'</span>]</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="bu">print</span>(text)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="bu">print</span>(summary)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>output:</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge-6" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-6" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-6"></a>
</h3>
<div class="callout-content">
<p>Use the huggingface library to access and use an open-source
domain-specific LLM for text classification. You can use the following
code to load the huggingface library and the pre-trained model and
tokenizer for text classification:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>text_classifier <span class="op">=</span> pipeline(<span class="st">"text-classification"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>...</span></code></pre>
</div>
<p>Use the text_classifier to classify the following text into one of
the categories: metals, ceramics, polymers, or composites. Print the
text and the predicted category and score.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>Text: <span class="st">"Polyethylene is a thermoplastic polymer that consists of long chains of ethylene monomers. It is one of the most common and widely used plastics in the world. It has many applications, such as packaging, bottles, containers, films, pipes, and cables. Polyethylene can be classified into different grades based on its density, molecular weight, branching, and crystallinity."</span></span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution7" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution7" aria-expanded="false" aria-controls="collapseSolution7">
  <h4 class="accordion-header" id="headingSolution7">Show me the solution</h4>
</button>
<div id="collapseSolution7" class="accordion-collapse collapse" data-bs-parent="#accordionSolution7" aria-labelledby="headingSolution7">
<div class="accordion-body">
<p>A:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>text_classifier <span class="op">=</span> pipeline(<span class="st">"text-classification"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Polyethylene is a thermoplastic polymer that consists of long chains of ethylene monomers. It is one of the most common and widely used plastics in the world. It has many applications, such as packaging, bottles, containers, films, pipes, and cables. Polyethylene can be classified into different grades based on its density, molecular weight, branching, and crystallinity."</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="bu">print</span>(text)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="bu">print</span>(text_classifier(text))</span></code></pre>
</div>
<pre><code><span></span>
<span><span class="va">output</span><span class="op">:</span> <span class="st">"Polyethylene is a thermoplastic polymer that consists of long chains of ethylene monomers. It is one of the most common and widely used plastics in the world. It has many applications, such as packaging, bottles, containers, films, pipes, and cables. Polyethylene can be classified into different grades based on its density, molecular weight, branching, and crystallinity."</span></span>
<span><span class="st">"[{'label': 'polymers', 'score': 0.9987659454345703}]"</span></span></code></pre>
</div>
</div>
</div>
</div>
<div id="challenge-7" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-7" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge-7"></a>
</h3>
<div class="callout-content">
<p>Use the huggingface library to access and use an open-source LLM for
text generation. You can use the following code to load the huggingface
library and the pre-trained model and tokenizer for text generation:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>text_generator <span class="op">=</span> pipeline(<span class="st">"text-generation"</span>)</span></code></pre>
</div>
<p>Use the text_generator to generate a paragraph of text based on the
following prompt: “The applications of nanomaterials in material science
are”. Print the prompt and the generated text.</p>
</div>
</div>
</div>
<div id="accordionSolution8" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution8" aria-expanded="false" aria-controls="collapseSolution8">
  <h4 class="accordion-header" id="headingSolution8">Show me the solution</h4>
</button>
<div id="collapseSolution8" class="accordion-collapse collapse" data-bs-parent="#accordionSolution8" aria-labelledby="headingSolution8">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>text_generator <span class="op">=</span> pipeline(<span class="st">"text-generation"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"The applications of nanomaterials in material science are"</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>generated_text <span class="op">=</span> text_generator(prompt)[<span class="dv">0</span>][<span class="st">'generated_text'</span>]</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="bu">print</span>(prompt)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="bu">print</span>(generated_text)</span></code></pre>
</div>
<pre><code>
output: "The applications of nanomaterials in material science are
The applications of nanomaterials in material science are diverse and promising. Nanomaterials are materials that have at least one dimension in the nanometer range (1-100 nm). Nanomaterials can exhibit novel physical, chemical, and biological properties that are different from their bulk counterparts, such as high surface area, quantum confinement, enhanced reactivity, and tunable functionality. Nanomaterials can be used for various purposes in material science, such as improving the performance and functionality of existing materials, creating new materials with unique properties, and enabling new functionalities and devices. Some examples of nanomaterials applications in material science are:

- Nanocomposites: Nanomaterials can be incorporated into other materials, such as polymers, metals, ceramics, or biomaterials, to form nanocomposites that have improved mechanical, thermal, electrical, optical, or magnetic properties. For instance, carbon nanotubes can be used to reinforce polymer composites and increase their strength, stiffness, and conductivity.
- Nanocoatings: Nanomaterials can be used to coat the surface of other materials, such as metals, glass, or plastics, to provide them with enhanced protection, durability, or functionality. For example, titanium dioxide nanoparticles can be used to coat glass and make it self-cleaning, anti-fogging, and anti-bacterial.
- Nanosensors: Nanomaterials can be used to sense and measure various physical, chemical, or biological parameters, such as temperature, pressure, strain, pH, or biomolecules. For example, gold nanoparticles can be used to detect and quantify the presence of specific DNA sequences or proteins by changing their color or fluorescence.
- Nanomedicine: Nanomaterials can be used for various biomedical applications, such as drug delivery, imaging, diagnosis, or therapy. For example, magnetic nanoparticles can be used to deliver drugs to specific target sites in the body by using an external magnetic field, or to enhance the contrast of magnetic resonance imaging (MRI).
</code></pre>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>LLMs are based on the transformer architecture.</li>
<li>BERT and GPT have distinct approaches to processing language.</li>
<li>Open source LLMs provide transparency and customization for research
applications.</li>
<li>Benchmarking with HELM offers a holistic view of model
performance.</li>
</ul></div>
</div>
</div>
<!-- Collect your link references at the bottom of your document -->
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-transformers.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-transformers.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Transformers for
        </a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html" rel="next">
          Next: Domain-Specific LLMs... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/06-llms.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:training@qcif.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.4" class="external-link">sandpaper (0.16.4)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.5" class="external-link">pegboard (0.7.5)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.2" class="external-link">varnish (1.0.2)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Large Language Models",
  "creativeWorkStatus": "active",
  "url": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "identifier": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "dateCreated": "2024-05-10",
  "dateModified": "2024-05-12",
  "datePublished": "2024-05-14"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

