<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Natural Language Processing for Research: Large Language Models</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="manifest" href="../site.webmanifest"><link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../06-llms.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Natural Language Processing for Research
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Natural Language Processing for Research
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="../aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Natural Language Processing for Research
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 64%" class="percentage">
    64%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 64%" aria-valuenow="64" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../06-llms.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction to Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-text-preprocessing.html">2. Introduction to Text Preprocessing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-text-analysis.html">3. Text Analysis</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-word-embedding.html">4. Word Embedding</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-transformers.html">5. Transformers for Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        6. Large Language Models
        </span>
      
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-domain-specific-llms.html">7. Domain-Specific LLMs</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-conclusion-final-project.html">8. Wrap-up and Final Project</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-transformers.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-transformers.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Transformers for
        </a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html" rel="next">
          Next: Domain-Specific LLMs... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Large Language Models</h1>
        <p>Last updated on 2024-05-10 |
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/06-llms.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are the main features of large language models?</li>
<li>How BERT is different from GPT models?</li>
<li>How can I use open-source LLMs, such as LLM examples in huggingface,
for research tasks?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Be able to explain the structure of large language models and their
main components</li>
<li>Identify differences between BERT and GPT.</li>
<li>Be able to use open-source LLMs, such as huggingface, for text
summarization, classification, and generation.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="introduction-to-llms">6.1. Introduction to LLMs<a class="anchor" aria-label="anchor" href="#introduction-to-llms"></a></h3>
<p>Large Language Models (LLMs) have become a cornerstone of modern
natural language processing (NLP). Since the introduction of the
transformer architecture in 2017, LLMs have leveraged this design to
achieve remarkable language understanding and generation capabilities.
In the previous episode, we discussed the transformer architecture,
which is integral to all LLMs, utilizing its encoder and decoder
components to process language.</p>
<p>LLMs have several key features. Gather in groups and discuss what are
these key components. Explain the key features in detail and compare
your thoughts with other group members:</p>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups-">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups-"></a></h2>
<p>Add your explanations below:</p>
<ol style="list-style-type: decimal"><li><p>Transformer Architecture: A neural network design that uses
self-attention mechanisms to weigh the influence of different parts of
the input data.</p></li>
<li><p>Pre-training: involves teaching LLMs to anticipate words in
sentences, using either bi-directional or uni-directional approaches,
(based on the LLM type), without the need for understanding or
experience.</p></li>
<li><hr></li>
<li><hr></li>
<li><hr></li>
<li><hr></li>
</ol><div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Solutions</h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<ol style="list-style-type: decimal"><li><p>Transformer Architecture: A neural network design that uses
self-attention mechanisms to weigh the influence of different parts of
the input data.</p></li>
<li><p>Pre-training: involves teaching LLMs to anticipate words in
sentences, using either bi-directional or uni-directional approaches,
(based on the LLM type), without the need for understanding or
experience.</p></li>
<li><p>Word/Token Embedding: The process of converting words or phrases
into numerical form (vectors) that computers can understand.</p></li>
<li><p>Context Window: The range of words the model considers for
predicting the next word or understanding the current word within a
sentence.</p></li>
<li><p>Parameters: The aspects of the model that are learned from
training data and determine the model’s behavior.</p></li>
<li><p>Transfer Learning: The process LLMs use to apply their prior
knowledge to new tasks.</p></li>
</ol><p>Thus, the completed graph will be:</p>
<figure><img src="../fig/llms_4.png" class="figure mx-auto d-block"></figure></div>
</div>
</div>
</div>
</div>
<figure><img src="../fig/llms_2.png" class="figure mx-auto d-block"></figure><div class="section level2 Discussion">
<h2 id="discuss-in-groups--1">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--1"></a></h2>
<p>What is DSL and why are they useful for research tasks? Think of some
examples of NLP tasks that require domain-specific LLMs, such as
literature review, patent analysis, or material discovery. How do
domain-specific LLMs improve the performance and accuracy of these
tasks?</p>
<figure><img src="../fig/llms_3.png" class="figure mx-auto d-block"></figure></div>
<p>We can categorize LLMs based on the transformer architecture. Let’s
have another look to the transformer architecture, this time divide it
into its two main components: Encoder and Decoder. How do you think we
should connect each one the following transformers to the correct
color?</p>
<figure><img src="../fig/llms_5.png" class="figure mx-auto d-block"></figure><p>• Encoders are used for understanding tasks like sentence
classification.</p>
<p>• Decoders excel in generative tasks like text generation.</p>
<p>• The combination of encoders and decoders in transformers allows
them to be versatile and perform a variety of tasks, from translation to
summarization, depending on the specific requirements of the task at
hand.</p>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: Encoder Vs. Decoder or BERT Vs. GPT</h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler2" aria-labelledby="headingSpoiler2">
<div class="accordion-body">
<p>We will see models like BERT use encoders for bidirectional
understanding, and models like GPT use decoders for generating coherent
text, making them suitable for chatbots or virtual assistants.</p>
</div>
</div>
</div>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--2">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--2"></a></h2>
<p>Think of some examples of traditional NLP models, such as n-gram
models, hidden Markov models, LSTMs and RNNs. How do large language
models differ from them in terms of architecture, data, and
performance?</p>
<div id="accordionSpoiler3" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler3" aria-expanded="false" aria-controls="collapseSpoiler3">
  <h3 class="accordion-header" id="headingSpoiler3">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Show details</h3>
</button>
<div id="collapseSpoiler3" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler3" aria-labelledby="headingSpoiler3">
<div class="accordion-body">
<p>Traditional NLP models, such as n-gram models, hidden Markov models
(HMMs), Long Short-Term Memory networks (LSTMs), and Recurrent Neural
Networks (RNNs), differ significantly from the recent LLMs. N-gram
models predict the next item in a sequence based on the previous ‘n-1’
items without any deep understanding of context. HMMs are statistical
models that output probabilities of sequences and are often used for
tasks like part-of-speech tagging. LSTMs and RNNs are types of neural
networks that can process sequences of data and are capable of learning
order dependence in sequence prediction.</p>
<p>Compared to these traditional models, LLMs have several key
differences: <strong>Architecture</strong>: Novel LLMs use transformer
architectures, which are more advanced than the simple recurrent units
of RNNs or the gated units of LSTMs. Transformers use self-attention to
weigh the influence of different parts of the input data, which is more
effective for understanding context. <strong>Data</strong>: Novel LLMs
are trained on massive datasets, often sourced from the internet, which
allows them to learn a wide variety of language patterns, common
knowledge, and even reasoning abilities. Traditional models typically
use smaller, more curated datasets. <strong>Performance</strong>: Novel
LLMs generally outperform traditional models in a wide range of language
tasks due to their ability to understand and generate human-like text.
They can capture subtleties and complexities of language that simpler
models cannot, leading to more accurate and coherent outputs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="bert">6.2. BERT<a class="anchor" aria-label="anchor" href="#bert"></a></h3>
<p>Bidirectional Encoder Representations from Transformers (BERT) is an
LLM that uses an encoder-only architecture from transformers. It is
designed to understand the context of a word based on all of its
surroundings (bidirectional context). Let’s guess the missing words in
the text below to comprehend the workings of BERT:</p>
</div>
<div class="section level2 Activity">
<h2 id="activity-fill-in-the-gap">Activity: Fill in the gap<a class="anchor" aria-label="anchor" href="#activity-fill-in-the-gap"></a></h2>
<p>“BERT is a revolutionary language model that uses an ______ (encoder)
to process words in a sentence. Unlike traditional models, it predicts
words based on the ______ (context) rather than in sequence. Its
training involves ______ (self-supervised learning), where words are
intentionally hidden, or ‘______’ (masked), and the model learns to
predict them. This results in rich ______ (embeddings) that capture the
nuanced meanings of words.”</p>
</div>
<div id="accordionSpoiler4" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler4" aria-expanded="false" aria-controls="collapseSpoiler4">
  <h3 class="accordion-header" id="headingSpoiler4">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: MLM &amp; NSP</h3>
</button>
<div id="collapseSpoiler4" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler4" aria-labelledby="headingSpoiler4">
<div class="accordion-body">
<p>Pre-training of language models involves a process where models like
BERT and GPT learn to predict words in sentences without specific task
training. This is achieved through methods like Masked Language Model
(MLM) for bi-directional models, which predict masked words using
surrounding context. MLM in BERT predicts missing words in a sentence by
masking them during training.</p>
<p>For Next Sentence Prediction (NSP) BERT learns to predict if two
sentences logically follow each other.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="gpt">6.3. GPT<a class="anchor" aria-label="anchor" href="#gpt"></a></h3>
<p>Generative Pretrained Transformer (GPT) models, on the other hand,
use a decoder-only architecture. They excel at generating coherent and
contextually relevant text. Check the following table that summarizes
three different LLMs. The middle column misses some information about
GPT models. With the help of your teammates complete the table and
explain the differences in the end.</p>
</div>
<div class="Activity">
<div class="section level2">
<h2 id="activity-fill-in-the-gap-1">Activity: Fill in the gap<a class="anchor" aria-label="anchor" href="#activity-fill-in-the-gap-1"></a></h2>
<p>Fill the in the gray boxes with correct explanations.</p>
<figure><img src="../fig/llms_6.png" class="figure mx-auto d-block"></figure><figure><img src="../fig/llms_7.png" class="figure mx-auto d-block"></figure></div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--3">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--3"></a></h2>
<p>From what you learned above how can you explain the differences
between the three LLM types? Discuss in groups and share your
answers.</p>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>We can see it as the processes of trying to understand a conversation
(BERT), versus trying to decide what to say next in the conversation
(GPT). BERT is like someone who listens to the entire conversation
before and after a word to really understand its meaning.</p>
<p>For example, in the sentence “I ate an apple,” BERT would look at
both “I ate an” and “apple” to figure out what <strong>“an”</strong>
refers to. It’s trained by playing a game of <strong>‘guess the missing
word,’</strong> where some words are hidden <strong>(masked)</strong>
and it has to use the context to fill in the blanks.</p>
<p>GPT, on the other hand, is like a storyteller who only needs to know
what was said before to continue the tale. It would take “I ate an” and
<strong>predict that the next word</strong> might be “apple.” It learns
by <strong>reading a lot of text</strong> and practicing how to predict
the next word in a sentence.</p>
<p>Both are smart in their own ways, but they’re used for different
types of language tasks. BERT is great for understanding the
<strong>context of words</strong>, while GPT is excellent at
<strong>generating new text</strong> based on what it’s seen before. The
following schematics demonstrate their performing differences:</p>
<figure><img src="../fig/llms_8.png" class="figure mx-auto d-block"></figure></div>
</div>
</div>
</div>
</div>
<div id="accordionSpoiler5" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler5" aria-expanded="false" aria-controls="collapseSpoiler5">
  <h3 class="accordion-header" id="headingSpoiler5">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: HELM: LLMs Comparison</h3>
</button>
<div id="collapseSpoiler5" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler5" aria-labelledby="headingSpoiler5">
<div class="accordion-body">
<p>Models are often benchmarked using standardized datasets and metrics.
The Holistic Evaluation of Language Models (HELM) by Stanford provides a
comprehensive framework for evaluating LLMs across multiple
dimensions.</p>
<figure><img src="../fig/llms_9.png" class="figure mx-auto d-block"></figure><p>GPT-4 models are outperforming other LLM models in terms of
accuracy.</p>
</div>
</div>
</div>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--4">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--4"></a></h2>
<p>What are some examples of LLMs, and how are they trained and used for
research tasks? Consider some of the main features and characteristics
of LLMs, such as transformer architecture, self-attention mechanism,
pre-training and fine-tuning, and embedding capabilities. How do these
features enable LLMs to perform various NLP tasks, such as text
classification, text generation, or question answering?</p>
</div>
<div class="section level3">
<h3 id="open-source-llms">6.4. Open-Source LLMs:<a class="anchor" aria-label="anchor" href="#open-source-llms"></a></h3>
<p>It is very important for researchers to openly have access to capable
LLMs for their studies. Fortunately, some companies are supporting
open-source LLMs. The BLOOM model, developed by the BigScience Workshop
in collaboration with Hugging Face and other organizations, was released
on July 6, 2022. It offers a wide range of model sizes, from 1.1 billion
to 176 billion parameters, and is licensed under the open RAIL-M v1.
BLOOM is known for its instruct models, coding capabilities,
customization finetuning, and being open source. It is more openly
accessible and benefits from a large community and extensive
support.</p>
<p>On the other hand, the LLaMA model, developed by Meta AI, was
released on February 24, 2023. It is available in four sizes: 7 billion,
13 billion, 33 billion, and 65 billion parameters. The license for LLaMA
is restricted to noncommercial use, and access is primarily for
researchers. Despite its smaller size, LLaMA is parameter-efficient and
has outperformed GPT-3 on many benchmarks. However, its accessibility is
more gated compared to BLOOM, and community support is limited to
approved researchers.</p>
<p>Now let’s summarize what we learned here in the following table:</p>
<figure><img src="../fig/llms_10.png" class="figure mx-auto d-block"></figure></div>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--5">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--5"></a></h2>
<p>What are the challenges and trade-offs of domain-specific LLMs, such
as data availability, model size, and complexity?</p>
<p>Consider some of the factors that affect the quality and reliability
of domain-specific LLMs, such as the amount and quality of
domain-specific data, the computational resources and time required for
training or fine-tuning, and the generalization and robustness of the
model. How do these factors pose problems or difficulties for
domain-specific LLMs and how can we overcome them?</p>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--6">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--6"></a></h2>
<p>What are some available approaches for creating domain-specific LLMs,
such as fine-tuning and knowledge distillation?</p>
<p>Consider some of the main steps and techniques for creating
domain-specific LLMs, such as selecting a general LLM, collecting and
preparing domain-specific data, training or fine-tuning the model, and
evaluating and deploying the model. How do these approaches differ from
each other and what are their advantages and disadvantages?</p>
</div>
<div class="section level3">
<h3 id="example">Example:<a class="anchor" aria-label="anchor" href="#example"></a></h3>
<p>Now let’s try One-shot and Few-shot prompting examples and see how it
can help us to enhance the sensitivity of the LLM to our field of study:
One-shot prompting involves providing the model with a single example to
follow. It’s like giving the model a hint about what you expect. We will
go through an example using Hugging Face’s transformers library:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># Load a pre-trained model and tokenizer</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"gpt2"</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span>model_name)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># One-shot example</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Translate 'Hello, how are you?' to French:</span><span class="ch">\n</span><span class="st">Bonjour, comment ça va?</span><span class="ch">\n</span><span class="st">Translate 'I am learning new things every day' to French:"</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>result <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Output the result</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code></pre>
</div>
<p>In this example, we provide the model with one translation example
and then ask it to translate a new sentence. The model uses the context
from the one-shot example to generate the translation.</p>
<p>But what if we have a Few-Shot Prompting? Few-shot prompting gives
the model several examples to learn from. This can improve the model’s
ability to understand and complete the task. Here is how you can
implement few-shot prompting:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Load a pre-trained model and tokenizer</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"gpt2"</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span>model_name)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># Few-shot examples</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""</span><span class="ch">\</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="st">Q: What is the capital of France?</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="st">A: Paris.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="st">Q: What is the largest mammal?</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="st">A: Blue whale.</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="st">Q: What is the human body's largest organ?</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="st">A: The skin.</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="st">Q: What is the currency of Japan?</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="st">A:"""</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>result <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="co"># Output the result</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code></pre>
</div>
<p>In this few-shot example, we provide the model with three
question-answer pairs before posing a new question. The model uses the
pattern it learned from the examples to answer the new question.</p>
<div id="challenge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge"></a>
</h3>
<div class="callout-content">
<p>To summarize this approach in a few steps, fill in the following
gaps: 1. Choose a Model: Select a <strong>—</strong> model from Hugging
Face that suits your task.</p>
<ol start="2" style="list-style-type: decimal"><li><p>Load the Model: Use the <strong>—</strong> function to load the
model and tokenizer.</p></li>
<li><p>Craft Your Prompt: Write a <strong>—</strong> that includes one
or more examples, depending on whether you’re doing one-shot or few-shot
prompting.</p></li>
<li><p>Generate Text: Call the <strong>—</strong> with your prompt to
generate the <strong>—</strong>.</p></li>
<li><p>Review the Output: Check the generated text to see if the model
followed the <strong>—</strong> correctly.</p></li>
</ol></div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ol style="list-style-type: decimal"><li><p>Choose a Model: Select a <strong>pre-trained</strong> model from
Hugging Face that suits your task.</p></li>
<li><p>Load the Model: Use the <strong>pipeline</strong> function to
load the model and tokenizer.</p></li>
<li><p>Craft Your Prompt: Write a <strong>prompt</strong> that includes
one or more examples, depending on whether you’re doing one-shot or
few-shot prompting.</p></li>
<li><p>Generate Text: Call the <strong>generator</strong> with your
prompt to generate the <strong>output</strong>.</p></li>
<li><p>Review the Output: Check the generated text to see if the model
followed the <strong>examples</strong> correctly.</p></li>
</ol></div>
</div>
</div>
</div>
<div id="accordionSpoiler6" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler6" aria-expanded="false" aria-controls="collapseSpoiler6">
  <h3 class="accordion-header" id="headingSpoiler6">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: Prompting Quality</h3>
</button>
<div id="collapseSpoiler6" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler6" aria-labelledby="headingSpoiler6">
<div class="accordion-body">
<p>Remember, the quality of the output heavily depends on the quality
and relevance of the examples you provide. It’s also important to note
that larger models tend to perform better at these tasks due to their
greater capacity to understand and generalize from examples.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>Domain-specific LLMs are essential for tasks that require
specialized knowledge.</li>
<li>Prompt engineering, RAG, fine-tuning, and training from scratch are
viable approaches to create DSLs.</li>
<li>A mixed prompting-RAG approach is often preferred for its balance
between performance and resource efficiency.</li>
<li>Training from scratch offers the highest quality output but requires
significant resources.</li>
</ul></div>
</div>
</div>
<!-- Collect your link references at the bottom of your document -->
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-transformers.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-transformers.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Transformers for
        </a>
        <a class="chapter-link float-end" href="../instructor/07-domain-specific-llms.html" rel="next">
          Next: Domain-Specific LLMs... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/06-llms.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:training@qcif.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.4" class="external-link">sandpaper (0.16.4)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.5" class="external-link">pegboard (0.7.5)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.2" class="external-link">varnish (1.0.2)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Large Language Models",
  "creativeWorkStatus": "active",
  "url": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "identifier": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/06-llms.html",
  "dateCreated": "2024-05-10",
  "dateModified": "2024-05-10",
  "datePublished": "2024-05-10"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

