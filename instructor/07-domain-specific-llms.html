<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Natural Language Processing for Research: Domain-Specific LLMs</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="manifest" href="../site.webmanifest"><link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../07-domain-specific-llms.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Natural Language Processing for Research
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Natural Language Processing for Research
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="../aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Natural Language Processing for Research
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 76%" class="percentage">
    76%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 76%" aria-valuenow="76" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../07-domain-specific-llms.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction to Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-text-preprocessing.html">2. Introduction to Text Preprocessing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-text-analysis.html">3. Text Analysis</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-word-embedding.html">4. Word Embedding</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-transformers.html">5. Transformers for Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-llms.html">6. Large Language Models</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        7. Domain-Specific LLMs
        </span>
      
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-conclusion-final-project.html">8. Wrap-up and Final Project</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/06-llms.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/08-conclusion-final-project.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/06-llms.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Large Language
        </a>
        <a class="chapter-link float-end" href="../instructor/08-conclusion-final-project.html" rel="next">
          Next: Wrap-up and Final... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Domain-Specific LLMs</h1>
        <p>Last updated on 2024-05-10 |
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/07-domain-specific-llms.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How can tune the LLMs to be domain-specific?</li>
<li>What are some available approaches to empower LLMs solve specific
research problems?</li>
<li>Which approach should I use for my research?</li>
<li>What are the challenges and trade-offs of domain-specific LLMs?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Be able to identify approaches by which LLMs can be tuned for
solving research problems.</li>
<li>Be able to use introductory approaches for creating domain-specific
LLMs.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="introduction-to-dsl-available-approaches">7.1. Introduction to DSL (Available Approaches)<a class="anchor" aria-label="anchor" href="#introduction-to-dsl-available-approaches"></a></h3>
<p>To enhance the response quality of an LLM for solving specific
problems we need to use strategies by which we can tune the LLM.
Generally, there are four ways to enhance the performance of LLMs:</p>
<div class="section level4">
<h4 id="prompt-optimization">1. Prompt Optimization:<a class="anchor" aria-label="anchor" href="#prompt-optimization"></a></h4>
<p>To elicit specific and accurate responses from LLMs by designing
prompts strategically.</p>
<p><strong>Zero-shot Prompting</strong>: This is the simplest form of
prompting where the LLM is given a task or question without any context
or examples. It relies on the LLM’s pre-existing knowledge to generate a
response.</p>
<p>Example: “What is the capital of France?” The LLM would respond with
“Paris” based on its internal knowledge.</p>
<p><strong>Few-shot Prompting</strong>: In this technique, the LLM is
provided with a few examples to demonstrate the expected response format
or content.</p>
<p>Example: To determine sentiment, you might provide examples like “I
love sunny days. (+1)” and “I hate traffic. (-1)” before asking the LLM
to analyze a new sentence.</p>
</div>
<div class="section level4">
<h4 id="retrieval-augmented-generation-rag">2. Retrieval Augmented Generation (RAG):<a class="anchor" aria-label="anchor" href="#retrieval-augmented-generation-rag"></a></h4>
<p>To supplement the LLM’s generative capabilities with information
retrieved from external databases or documents.</p>
<p><strong>Retrieval</strong>: The LLM queries a database to find
relevant information that can inform its response.</p>
<p>Example: If asked about recent scientific discoveries, the LLM might
retrieve articles or papers on the topic.</p>
<p><strong>Generation</strong>: After retrieving the information, the
LLM integrates it into a coherent response.</p>
<p>Example: Using the retrieved scientific articles, the LLM could
generate a summary of the latest findings in a particular field.</p>
</div>
<div class="section level4">
<h4 id="fine-tuning">3. Fine-Tuning:<a class="anchor" aria-label="anchor" href="#fine-tuning"></a></h4>
<p>To adapt a general-purpose LLM to excel at a specific task or within
a particular domain.</p>
<p><strong>Language Modeling Task Fine-Tuning</strong>: This involves
training the LLM on a large corpus of text to improve its ability to
predict the next word or phrase in a sentence.</p>
<p>Example: An LLM fine-tuned on legal documents would become better at
generating text that resembles legal writing.</p>
<p><strong>Supervised Q&amp;A Fine-Tuning</strong>: Here, the LLM is
trained on a dataset of question-answer pairs to enhance its performance
on Q&amp;A tasks.</p>
<p>Example: An LLM fine-tuned with medical Q&amp;A pairs would provide
more accurate responses to health-related inquiries.</p>
</div>
<div class="section level4">
<h4 id="training-from-scratch">4. Training from Scratch:<a class="anchor" aria-label="anchor" href="#training-from-scratch"></a></h4>
<p>Builds a model specifically for a domain, using relevant data from
the ground up.</p>
</div>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups-">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups-"></a></h2>
<p>Which approach do you think is more computation-intensive? Which is
more accurate? How are these qualities related? Evaluate the trade-offs
between fine-tuning and other approaches.</p>
<figure><img src="../fig/dsllms_1.png" class="figure mx-auto d-block"></figure></div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--1">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--1"></a></h2>
<p>What is DSL and why are they useful for research tasks? Think of some
examples of NLP tasks that require domain-specific LLMs, such as
literature review, patent analysis, or material discovery. How do
domain-specific LLMs improve the performance and accuracy of these
tasks?</p>
<figure><img src="../fig/dsllms_2.png" class="figure mx-auto d-block"></figure></div>
<div class="section level3">
<h3 id="prompting">7.2. Prompting<a class="anchor" aria-label="anchor" href="#prompting"></a></h3>
<p>For research applications where highly reliable answers are crucial,
Prompt Engineering combined with Retrieval-Augmented Generation (RAG) is
often the most suitable approach. This combination allows for
flexibility and high-quality outputs by leveraging both the generative
capabilities of LLMs and the precision of domain-specific data
sources:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>Install the Hugging Face libraries</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="op">!</span>pip install transformers datasets</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Initialize the zero-shot classification pipeline</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>classifier <span class="op">=</span> pipeline(<span class="st">"zero-shot-classification"</span>, model<span class="op">=</span><span class="st">"facebook/bart-large-mnli"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co"># Example research question</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>question <span class="op">=</span> <span class="st">"What is the role of CRISPR-Cas9 in genome editing?"</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># Candidate topics to classify the question</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>topics <span class="op">=</span> [<span class="st">"Biology"</span>, <span class="st">"Technology"</span>, <span class="st">"Healthcare"</span>, <span class="st">"Genetics"</span>, <span class="st">"Ethics"</span>]</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co"># Perform zero-shot classification</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>result <span class="op">=</span> classifier(question, candidate_labels<span class="op">=</span>topics)</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="co"># Output the results</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Question: </span><span class="sc">{</span>question<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classified under topics with the following scores:"</span>)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a><span class="cf">for</span> label, score <span class="kw">in</span> <span class="bu">zip</span>(result[<span class="st">'labels'</span>], result[<span class="st">'scores'</span>]):</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: Be careful when fine-tuning a model</h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<p>When fine-tuning a BERT model from Hugging Face, for instance, it is
essential to approach the process with precision and care.</p>
<p>Begin by thoroughly understanding <strong>BERT’s
architecture</strong> and the specific task at hand to select the most
suitable model variant and hyperparameters.</p>
<p><strong>Prepare your dataset</strong> meticulously, ensuring it is
clean, well-represented, and split correctly to avoid <strong>data
leakage and overfitting</strong>.</p>
<p>Hyperparameter selection, such as learning rates and batch sizes,
should be made with consideration, and <strong>regularization</strong>
techniques like dropout should be employed to enhance the model’s
ability to generalize.</p>
<p><strong>Evaluate</strong> the model’s performance using appropriate
metrics and address any class imbalances with weighted loss functions or
similar strategies. Save checkpoints to preserve progress and document
every step of the fine-tuning process for transparency and
reproducibility.</p>
<p><strong>Ethical considerations</strong> are paramount; strive for a
model that is fair and unbiased. Ensure compliance with data protection
regulations, especially when handling sensitive information.</p>
<p>Lastly, manage <strong>computational resources</strong> wisely and
engage with the Hugging Face community for additional support.
Fine-tuning is iterative, and success often comes through continuous
experimentation and learning.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--2">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--2"></a></h2>
<p>Guess the following architecture belongs to which optimization
strategy:</p>
<figure><img src="../fig/dsllms_3.png" class="figure mx-auto d-block"></figure><p>Figure. LLMs optimization (source)</p>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--3">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--3"></a></h2>
<p>What are the challenges and trade-offs of domain-specific LLMs, such
as data availability, model size, and complexity?</p>
<p>Consider some of the factors that affect the quality and reliability
of domain-specific LLMs, such as the amount and quality of
domain-specific data, the computational resources and time required for
training or fine-tuning, and the generalization and robustness of the
model. How do these factors pose problems or difficulties for
domain-specific LLMs and how can we overcome them?</p>
</div>
<div class="section level2 Discussion">
<h2 id="discuss-in-groups--4">Discuss in groups.<a class="anchor" aria-label="anchor" href="#discuss-in-groups--4"></a></h2>
<p>What are some available approaches for creating domain-specific LLMs,
such as fine-tuning and knowledge distillation?</p>
<p>Consider some of the main steps and techniques for creating
domain-specific LLMs, such as selecting a general LLM, collecting and
preparing domain-specific data, training or fine-tuning the model, and
evaluating and deploying the model. How do these approaches differ from
each other and what are their advantages and disadvantages?</p>
</div>
<div class="section level3">
<h3 id="example">Example:<a class="anchor" aria-label="anchor" href="#example"></a></h3>
<p>Now let’s try One-shot and Few-shot prompting examples and see how it
can help us to enhance the sensitivity of the LLM to our field of study:
One-shot prompting involves providing the model with a single example to
follow. It’s like giving the model a hint about what you expect. We will
go through an example using Hugging Face’s transformers library:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Load a pre-trained model and tokenizer</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"gpt2"</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span>model_name)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># One-shot example</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Translate 'Hello, how are you?' to French:</span><span class="ch">\n</span><span class="st">Bonjour, comment ça va?</span><span class="ch">\n</span><span class="st">Translate 'I am learning new things every day' to French:"</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>result <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># Output the result</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code></pre>
</div>
<p>In this example, we provide the model with one translation example
and then ask it to translate a new sentence. The model uses the context
from the one-shot example to generate the translation. But what if we
have a Few-Shot Prompting? Few-shot prompting gives the model several
examples to learn from. This can improve the model’s ability to
understand and complete the task.</p>
<p>Here is how you can implement few-shot prompting:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Load a pre-trained model and tokenizer</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"gpt2"</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span>model_name)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co"># Few-shot examples</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""</span><span class="ch">\</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="st">Q: What is the capital of France?</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="st">A: Paris.</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="st">Q: What is the largest mammal?</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="st">A: Blue whale.</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="st">Q: What is the human body's largest organ?</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="st">A: The skin.</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="st">Q: What is the currency of Japan?</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="st">A:"""</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>result <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co"># Output the result</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code></pre>
</div>
<p>In this few-shot example, we provide the model with three
question-answer pairs before posing a new question. The model uses the
pattern it learned from the examples to answer the new question.</p>
<div id="challenge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge" class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge"></a>
</h3>
<div class="callout-content">
<p>To summarize this approach in a few steps, fill in the following
gaps: 1. Choose a Model: Select a <strong>—</strong> model from Hugging
Face that suits your task.</p>
<ol start="2" style="list-style-type: decimal"><li><p>Load the Model: Use the <strong>—</strong> function to load the
model and tokenizer.</p></li>
<li><p>Craft Your Prompt: Write a <strong>—</strong> that includes one
or more examples, depending on whether you’re doing one-shot or few-shot
prompting.</p></li>
<li><p>Generate Text: Call the <strong>—</strong> with your prompt to
generate the <strong>—</strong>.</p></li>
<li><p>Review the Output: Check the generated text to see if the model
followed the <strong>—</strong> correctly.</p></li>
</ol></div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal"><li><p>Choose a Model: Select a <strong>pre-trained</strong> model from
Hugging Face that suits your task.</p></li>
<li><p>Load the Model: Use the <strong>pipeline</strong> function to
load the model and tokenizer.</p></li>
<li><p>Craft Your Prompt: Write a <strong>prompt</strong> that includes
one or more examples, depending on whether you’re doing one-shot or
few-shot prompting.</p></li>
<li><p>Generate Text: Call the <strong>generator</strong> with your
prompt to generate the <strong>output</strong>.</p></li>
<li><p>Review the Output: Check the generated text to see if the model
followed the <strong>examples</strong> correctly.</p></li>
</ol></div>
</div>
</div>
</div>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>Heads-up: Prompting Quality</h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" aria-labelledby="headingSpoiler2" data-bs-parent="#accordionSpoiler2">
<div class="accordion-body">
<p>Remember, the quality of the output heavily depends on the quality
and relevance of the examples you provide. It’s also important to note
that larger models tend to perform better at these tasks due to their
greater capacity to understand and generalize from examples.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>Domain-specific LLMs are essential for tasks that require
specialized knowledge.</li>
<li>Prompt engineering, RAG, fine-tuning, and training from scratch are
viable approaches to create DSLs.</li>
<li>A mixed prompting-RAG approach is often preferred for its balance
between performance and resource efficiency.</li>
<li>Training from scratch offers the highest quality output but requires
significant resources.</li>
</ul></div>
</div>
</div>
<!-- Collect your link references at the bottom of your document -->
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/06-llms.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/08-conclusion-final-project.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/06-llms.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Large Language
        </a>
        <a class="chapter-link float-end" href="../instructor/08-conclusion-final-project.html" rel="next">
          Next: Wrap-up and Final... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/07-domain-specific-llms.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:training@qcif.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.4" class="external-link">sandpaper (0.16.4)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.5" class="external-link">pegboard (0.7.5)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.2" class="external-link">varnish (1.0.2)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/07-domain-specific-llms.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Domain-Specific LLMs",
  "creativeWorkStatus": "active",
  "url": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/07-domain-specific-llms.html",
  "identifier": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/instructor/07-domain-specific-llms.html",
  "dateCreated": "2024-05-10",
  "dateModified": "2024-05-10",
  "datePublished": "2024-05-12"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

