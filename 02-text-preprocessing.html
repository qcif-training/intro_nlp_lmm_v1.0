<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Natural Language Processing for Research: Introduction to Text Preprocessing</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"><link rel="manifest" href="site.webmanifest"><link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/02-text-preprocessing.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Natural Language Processing for Research
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Natural Language Processing for Research
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Natural Language Processing for Research
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 10%" class="percentage">
    10%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 10%" aria-valuenow="10" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/02-text-preprocessing.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction to Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        2. Introduction to Text Preprocessing
        </span>
      </button>
    </div><!--/div.accordion-header-->
        
    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#sentence-segmentation">2.1. Sentence Segmentation</a></li>
<li><a href="#tokeniziation">2.2. Tokeniziation</a></li>
<li><a href="#deep-learning-workflow">Deep Learning Workflow</a></li>
<li><a href="#custom-image-data">Custom image data</a></li>
<li><a href="#pre-existing-image-data">Pre-existing image data</a></li>
<li><a href="#data-preprocessing-completed">Data preprocessing completed!</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-text-analysis.html">3. Text Analysis</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-word-embedding.html">4. Word Embedding</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-transformers.html">5. Transformers for Natural Language Processing</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-llms.html">6. Large Language Models</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-domain-specific-llms.html">7. Domain-Specific LLMs</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-conclusion-final-project.html">8. Wrap-up and Final Project</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="01-introduction.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="03-text-analysis.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="01-introduction.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Introduction to
        </a>
        <a class="chapter-link float-end" href="03-text-analysis.html" rel="next">
          Next: Text Analysis... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Introduction to Text Preprocessing</h1>
        <p>Last updated on 2024-05-12 |
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/02-text-preprocessing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How can I prepare data for NLP text analysis?</li>
<li>How can I use spaCy for text preprocessing?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Define text preprocessing and its purpose for NLP tasks.</li>
<li>Perform sentence segmentation, tokenization lemmatization, and
stop-words removal, using spaCy.</li>
</ul></div>
</div>
</div>
</div>
</div>
<p>Text preprocessing is the method of cleaning and preparing text data
for use in NLP. This step is vital because it transforms raw data into a
format that can be analyzed and used effectively by NLP algorithms.</p>
<section id="sentence-segmentation"><h2 class="section-heading">2.1. Sentence Segmentation<a class="anchor" aria-label="anchor" href="#sentence-segmentation"></a>
</h2>
<hr class="half-width"><p>Sentence segmentation divides a text into its constituent sentences,
which is essential for understanding the structure and flow of the
content. We start with a field-specific text example and see how it
works. We can start with a paragraph about perovskite nanocrystals from
the context of material engineering. Divide it into sentences.</p>
<p>We can use the open-source library, spaCy, to perform this task.
First, we import the spaCy library:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> spacy</span></code></pre>
</div>
<p>Then we need to Load the English language model:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span></code></pre>
</div>
<p>We can store our text here:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>perovskite_text <span class="op">=</span> <span class="st">"Perovskite nanocrystals are a class of semiconductor nanocrystals with unique properties that distinguish them from traditional quantum dots. These nanocrystals have an ABX3 composition, where 'A' can be cesium, methylammonium (MA), or formamidinium (FA); 'B' is typically lead or tin; and 'X' is a halogen ion like chloride, bromide, or iodide. Their remarkable optoelectronic properties, such as high photoluminescence quantum yields and tunable emission across the visible spectrum, make them ideal for applications in light-emitting diodes, lasers, and solar cells."</span></span></code></pre>
</div>
<p>Now we process the text with spaCy:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>doc <span class="op">=</span> nlp(perovskite_text)</span></code></pre>
</div>
<p>To extract sentences from the processed text we use the
<em>list()</em> function:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>sentences <span class="op">=</span> <span class="bu">list</span>(doc.sents)</span></code></pre>
</div>
<p>We use <em>for loop</em> and <em>print()</em> function to output each
sentence to show the segmentation:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>   <span class="bu">print</span>(sentence.perovskite_text)</span></code></pre>
</div>
<pre><code>Output: Perovskite nanocrystals are a class of semiconductor nanocrystals with unique properties that distinguish them from traditional quantum dots.
These nanocrystals have an ABX3 composition, where 'A' can be cesium, methylammonium (MA), or formamidinium (FA); 'B' is typically lead or tin; and 'X' is a halogen ion like chloride, bromide, or iodide.
Their remarkable optoelectronic properties, such as high photoluminescence quantum yields and tunable emission across the visible spectrum, make them ideal for applications in light-emitting diodes, lasers, and solar cells.</code></pre>
<div id="discussion" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="discussion" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion"></a>
</h3>
<div class="callout-content">
<p>Q: Let’s try again by completing the code below to segment sentences
from a paragraph about “your field of research”:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>nlp <span class="op">=</span> _____.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Add the paragraph about your field of research here</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"___"</span> </span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>doc <span class="op">=</span> nlp(___)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># Fill in the blank to extract sentences:</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>sentences <span class="op">=</span> <span class="bu">list</span>(______) </span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Fill in the blank to print each sentence</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>  <span class="bu">print</span>(______)  </span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>A:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># Add the paragraph about your field of research here</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"***"</span> <span class="co"># varies based on your field of research</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>doc <span class="op">=</span> nlp(text)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># Fill in the blank to extract sentences:</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>sentences <span class="op">=</span> <span class="bu">list</span>(doc.sents) </span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co"># Fill in the blank to print each sentence</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>  <span class="bu">print</span>(sentence.text)  </span></code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="tokeniziation"><h2 class="section-heading">2.2. Tokeniziation<a class="anchor" aria-label="anchor" href="#tokeniziation"></a>
</h2>
<hr class="half-width"><p>As already mentioned, in the first episode, Tokenization breaks down
text into individual words or tokens, which is a fundamental step for
many NLP tasks.</p>
<div id="discussion-1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="discussion-1" class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion-1"></a>
</h3>
<div class="callout-content">
<p>Teamwork: To better understand how it works let’s Match tokens from
the provided paragraph about perovskite nanocrystals with similar tokens
from another scientific text. This helps in understanding the common
vocabulary used in the scientific literature. Using the sentences we
listed in the previous section, we can see how Tokenization performs.
Assuming ‘sentences’ is a list of sentences from the previous example,
choose a sentence to tokenize:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>sentence_to_tokenize <span class="op">=</span> sentences[<span class="dv">0</span>]</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># Tokenize the chosen sentence by using a list comprehension:</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>tokens <span class="op">=</span> [token.perovskite_text <span class="cf">for</span> token <span class="kw">in</span> sentence_to_tokenize]</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co"># We can print the tokens:</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="bu">print</span>(tokens)</span></code></pre>
</div>
<pre><code>Output: ['Perovskite', 'nanocrystals', 'are', 'a', 'class', 'of', 'semiconductor', 'nanocrystals', 'with', 'unique', 'properties', 'that', 'distinguish', 'them', 'from', 'traditional', 'quantum', 'dots', '.']</code></pre>
<p>Tokenization is not just about splitting text into words; it’s about
understanding the boundaries of words and symbols in different contexts,
which can vary greatly between languages and even within the same
language in different settings.</p>
</div>
</div>
</div>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<p>Tokenization is very important for text analysis tasks such as
sentiment analysis. Here we can compare two different texts from
different fields and see how their associated tokens are different:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>perovskite_tokens <span class="op">=</span> [token.text <span class="cf">for</span> token <span class="kw">in</span> nlp(perovskite_text)]</span></code></pre>
</div>
<p>Now, we can add a new text from the trading context for comparison.
Tokenization of a trading text can be performed similarly to the
previous text.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>trading_text <span class="op">=</span> <span class="st">"Trading strategies often involve analyzing patterns and executing trades based on predicted market movements. Successful traders analyze trends and volatility to make informed decisions."</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>trading_tokens <span class="op">=</span> [token.text <span class="cf">for</span> token <span class="kw">in</span> nlp(trading_text)]</span></code></pre>
</div>
<p>We can see the results by using <em>print()</em> function. The tokens
from both texts:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Perovskite Tokens:"</span>, perovskite_tokens)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trading Tokens:"</span>, trading_tokens)</span></code></pre>
</div>
<pre><code>Output: 
Perovskite Tokens: ['Perovskite', 'nanocrystals', 'are', 'a', 'class', 'of', 'semiconductor', 'nanocrystals', 'with', 'unique', 'properties', 'that', 'distinguish', 'them', 'from', 'traditional', 'quantum', 'dots', '.']
Trading Tokens: ['Trading', 'strategies', 'often', 'involve', 'analyzing', 'patterns', 'and', 'executing', 'trades', 'based', 'on', 'predicted', 'market', 'movements', '.', 'Successful', 'traders', 'analyze', 'trends', 'and', 'volatility', 'to', 'make', 'informed', 'decisions', '.']</code></pre>
<p>The tokens from the perovskite text will be specific to materials
science, while the trading tokens will include terms related to market
analysis. The scientific texts may use more complex and compound words,
while trading texts might include more action-oriented and analytical
language. This comparison helps in understanding the specialized
language used in different fields.</p>
</div>
</div>
</div>
<div id="chemistry-joke" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="chemistry-joke" class="callout-inner">
<h3 class="callout-title">Chemistry Joke<a class="anchor" aria-label="anchor" href="#chemistry-joke"></a>
</h3>
<div class="callout-content">
<p>Q: If you aren’t part of the solution, then what are you?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>A: part of the precipitate</p>
</div>
</div>
</div>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>What Else Might We Use A Spoiler For?</h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<ul><li>
</li></ul></div>
</div>
</div>
</div>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout2"></a>
</h3>
<div class="callout-content">
<p>This is a callout block. It contains at least three colons</p>
</div>
</div>
</div>
</section><section id="deep-learning-workflow"><h2 class="section-heading">Deep Learning Workflow<a class="anchor" aria-label="anchor" href="#deep-learning-workflow"></a>
</h2>
<hr class="half-width"><p>Let’s start over from the beginning of our workflow.</p>
<div class="section level3">
<h3 id="step-1--formulate-outline-the-problem">Step 1. Formulate/ Outline the problem<a class="anchor" aria-label="anchor" href="#step-1--formulate-outline-the-problem"></a></h3>
<p>Firstly we must decide what it is we want our Deep Learning system to
do. This lesson is all about image classification and our aim is to put
an image into one of ten categories: airplane, automobile, bird, cat,
deer, dog, frog, horse, ship, or truck</p>
</div>
<div class="section level3">
<h3 id="step-2--identify-inputs-and-outputs">Step 2. Identify inputs and outputs<a class="anchor" aria-label="anchor" href="#step-2--identify-inputs-and-outputs"></a></h3>
<p>Next we identify the inputs and outputs of the neural network. In our
case, the data is images and the inputs could be the individual pixels
of the images.</p>
<p>We are performing a classification problem and we want to output one
category for each image.</p>
</div>
<div class="section level3">
<h3 id="step-3--prepare-data">Step 3. Prepare data<a class="anchor" aria-label="anchor" href="#step-3--prepare-data"></a></h3>
<p>Deep Learning requires extensive training using example data which
tells the network what output it should produce for a given input. In
this workshop, our network will be trained on a series of images and
told what they contain. Once the network is trained, it should be able
to take another image and correctly classify its contents.</p>
<p>Depending on your situation, you will prepare your own custom data
for training or use pre-existing data.</p>
<div id="challenge-how-much-data-do-you-need-for-deep-learning" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-how-much-data-do-you-need-for-deep-learning" class="callout-inner">
<h3 class="callout-title">CHALLENGE How much data do you need for Deep
Learning?<a class="anchor" aria-label="anchor" href="#challenge-how-much-data-do-you-need-for-deep-learning"></a>
</h3>
<div class="callout-content">
<p>The rise of Deep Learning is partially due to the increased
availability of very large datasets. But how much data do you actually
need to train a Deep Learning model?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3">Show me the solution</h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Unfortunately, this question is not easy to answer. It depends, among
other things, on the complexity of the task (which you often do not know
beforehand), the quality of the available dataset and the complexity of
the network. For complex tasks with large neural networks, adding more
data often improves performance. However, this is also not a generic
truth: if the data you add is too similar to the data you already have,
it will not give much new information to the neural network.</p>
<p>In case you have too little data available to train a complex network
from scratch, it is sometimes possible to use a pretrained network that
was trained on a similar problem. Another trick is data augmentation,
where you expand the dataset with artificial data points that could be
real. An example of this is mirroring images when trying to classify
cats and dogs. An horizontally mirrored animal retains the label, but
exposes a different view.</p>
</div>
</div>
</div>
</div>
</div>
</section><section id="custom-image-data"><h2 class="section-heading">Custom image data<a class="anchor" aria-label="anchor" href="#custom-image-data"></a>
</h2>
<hr class="half-width"><p>In some cases, you will create your own set of labelled images.</p>
<p>The steps to prepare your own custom image data include:</p>
<p><strong>Custom data i. Data collection and Labeling:</strong></p>
<p>For image classification the label applies to the entire image;
object detection requires bounding boxes around objects of interest, and
instance or semantic segmentation requires each pixel to be
labelled.</p>
<p>There are a number of open source software used to label your
dataset, including:</p>
<ul><li>(Visual Geometry Group) <a href="https://www.robots.ox.ac.uk/~vgg/software/via/" class="external-link">VGG Image
Annotator</a> (VIA)</li>
<li>
<a href="https://imagej.net/" class="external-link">ImageJ</a> can be extended with
plugins for annotation</li>
<li>
<a href="https://github.com/jsbroks/coco-annotator" class="external-link">COCO
Annotator</a> is designed specifically for creating annotations
compatible with Common Objects in Context (COCO) format</li>
</ul><p><strong>Custom data ii. Data preprocessing:</strong></p>
<p>This step involves various tasks to enhance the quality and
consistency of the data:</p>
<ul><li><p><strong>Resizing</strong>: Resize images to a consistent
resolution to ensure uniformity and reduce computational load.</p></li>
<li><p><strong>Augmentation</strong>: Apply random transformations
(e.g., rotations, flips, shifts) to create new variations of the same
image. This helps improve the model’s robustness and generalisation by
exposing it to more diverse data.</p></li>
<li><p><strong>Normalisation</strong>: Scale pixel values to a common
range, often between 0 and 1 or -1 and 1. Normalisation helps the model
converge faster during training.</p></li>
<li><p><strong>Label encoding</strong> is a technique used to represent
categorical data with numerical labels.</p></li>
<li><p><strong>Data Splitting</strong>: Split the data set into separate
parts to have one for training, one for evaluating the model’s
performance during training, and one reserved for the final evaluation
of the model’s performance.</p></li>
</ul><p>Before jumping into these specific preprocessing tasks, it’s
important to understand that images on a computer are stored as
numerical representations or simplified versions of the real world.
Therefore it’s essential to take some time to understand these numerical
abstractions.</p>
<div class="section level3">
<h3 id="pixels">Pixels<a class="anchor" aria-label="anchor" href="#pixels"></a></h3>
<p>Images on a computer are stored as rectangular arrays of hundreds,
thousands, or millions of discrete “picture elements,” otherwise known
as pixels. Each pixel can be thought of as a single square point of
coloured light.</p>
<p>For example, consider this image of a Jabiru, with a square area
designated by a red box:</p>
<figure><img src="fig/02_Jabiru_TGS_marked.jpg" alt="Jabiru image that is 552 pixels wide and 573 pixels high. A red square around the neck region indicates the area to zoom in on." class="figure mx-auto d-block"></figure><p>Now, if we zoomed in close enough to the red box, the individual
pixels would stand out:</p>
<figure><img src="fig/02_Jabiru_TGS_marked_zoom_enlarged.jpg" alt="zoomed in area of Jabiru where the individual pixels stand out" class="figure mx-auto d-block"></figure><p>Note each square in the enlarged image area (i.e. each pixel) is all
one colour, but each pixel can be a different colour from its
neighbours. Viewed from a distance, these pixels seem to blend together
to form the image.</p>
</div>
<div class="section level3">
<h3 id="working-with-pixels">Working with Pixels<a class="anchor" aria-label="anchor" href="#working-with-pixels"></a></h3>
<p>As noted, in practice, real world images will typically be made up of
a vast number of pixels, and each of these pixels will be one of
potentially millions of colours.</p>
<p>In python, an image can represented as a 2- or 3-dimensional array,
where each element corresponds to a pixel value in the image. In the
context of images, these arrays often have dimensions for height, width,
and colour channels (if applicable).</p>
<p>Let us start with the Jabiru image.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># load the required packages</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> img_to_array</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> load_img</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co"># specify the image path</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>new_img_path <span class="op">=</span> <span class="st">"../data/Jabiru_TGS.JPG"</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co"># read in the image with default arguments</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>new_img_pil <span class="op">=</span> load_img(new_img_path)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co"># check the image class and size</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Image class :'</span>, new_img_pil.__class__)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Image size'</span>, new_img_pil.size)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Image class : &lt;class 'PIL.JpegImagePlugin.JpegImageFile'&gt;
Image size (552, 573)</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="image-dimensions---resizing">Image Dimensions - Resizing<a class="anchor" aria-label="anchor" href="#image-dimensions---resizing"></a></h3>
<p>The new image has shape <code>(573, 552, 3)</code>, meaning it is
much larger in size, 573x552 pixels; a rectangle instead of a square;
and consists of three colour channels (RGB).</p>
<p>Recall from the introduction that our training data set consists of
50000 images of 32x32 pixels and three channels.</p>
<p>To reduce the computational load and ensure all of our images have a
uniform size, we need to choose an image resolution (or size in pixels)
and ensure all of the images we use are resized to that shape to be
consistent.</p>
<p>There are a couple of ways to do this in python but one way is to
specify the size you want using an argument to the
<code>load_img()</code> function from <code>keras.utils</code>.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># read in the image and specify the target size</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>new_img_pil_small <span class="op">=</span> load_img(new_img_path, target_size<span class="op">=</span>(<span class="dv">32</span>,<span class="dv">32</span>))</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co"># confirm the image class and size</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Resized image class :'</span>, new_img_pil_small.__class__)</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Resized image size'</span>, new_img_pil_small.size) </span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Resized image class : &lt;class 'PIL.Image.Image'&gt;
Resized image size (32, 32)</code></pre>
</div>
<p>Of course, if there are a large number of images to preprocess you do
not want to copy and paste these steps for each image! Fortunately,
Keras has a solution: <a href="https://keras.io/api/data_loading/image/" class="external-link">tf.keras.utils.image_dataset_from_directory</a></p>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>WANT TO KNOW MORE: Python image libraries</h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" aria-labelledby="headingSpoiler2" data-bs-parent="#accordionSpoiler2">
<div class="accordion-body">
<p>Two of the most commonly used libraries for image representation and
manipulation are NumPy and Pillow (PIL). Additionally, when working with
deep learning frameworks like TensorFlow and PyTorch, images are often
represented as tensors within these frameworks.</p>
<ul><li>NumPy is a powerful library for numerical computing in Python. It
provides support for creating and manipulating arrays, which can be used
to represent images as multidimensional arrays.
<ul><li><code>import numpy as np</code></li>
</ul></li>
<li>The Pillow library provides functions to open, manipulate, and save
various image file formats. It represents images using its own Image
class.
<ul><li><code>from PIL import Image</code></li>
<li>
<a href="https://pillow.readthedocs.io/en/latest/reference/Image.html" class="external-link">PIL
Image Module</a> documentation</li>
</ul></li>
<li>TensorFlow images are often represented as tensors that have
dimensions for batch size, height, width, and colour channels. This
framework provide tools to load, preprocess, and work with image data
seamlessly.
<ul><li><code>from tensorflow import keras</code></li>
<li>
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image" class="external-link">image
preprocessing</a> documentation</li>
<li>Note Keras image functions also use PIL</li>
</ul></li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="image-augmentation">Image augmentation<a class="anchor" aria-label="anchor" href="#image-augmentation"></a></h3>
<p>There are several ways to augment your data to increase the diversity
of the training data and improve model robustness.</p>
<ul><li>Geometric Transformations
<ul><li>rotation, scaling, zooming, cropping</li>
</ul></li>
<li>Flipping or Mirroring
<ul><li>some classes, like horse, have a different shape when facing left or
right and you want your model to recognize both</li>
</ul></li>
<li>Colour properties
<ul><li>brightness, contrast, or hue</li>
<li>these changes simulate variations in lighting conditions</li>
</ul></li>
</ul><p>We will not perform image augmentation in this lesson, but it is
important that you are aware of this type of data preparation because it
can make a big difference in your model’s ability to predict outside of
your training data.</p>
<p>Information about these operations are included in the Keras document
for <a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/" class="external-link">Image
augmentation layers</a>.</p>
</div>
<div class="section level3">
<h3 id="normalisation">Normalisation<a class="anchor" aria-label="anchor" href="#normalisation"></a></h3>
<p>Image RGB values are between 0 and 255. As input for neural networks,
it is better to have small input values. The process of converting the
RGB values to be between 0 and 1 is called
<strong>normalization</strong>.</p>
<p>Before we can normalize our image values we must convert the image to
an numpy array.</p>
<p>We introduced how to do this in <a href="01-introduction.html">Episode 01 Introduction to Deep Learning</a>
but what you may not have noticed is that the
<code>keras.datasets.cifar10.load_data</code> function did the
conversion for us whereas now we will do it ourselves.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># first convert the image into an array for normalization</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>new_img_arr <span class="op">=</span> img_to_array(new_img_pil_small)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co"># confirm the image class and shape</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Converted image class  :'</span>, new_img_arr.__class__)</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Converted image shape'</span>, new_img_arr.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Converted image class  : &lt;class 'numpy.ndarray'&gt;
Converted image shape (32, 32, 3)</code></pre>
</div>
<p>Now that the image is an array, we can normalize the values. Let us
also investigate the image values before and after we normalize
them.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># inspect pixel values before and after normalisation</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co"># extract the min, max, and mean pixel values BEFORE</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'BEFORE normalization'</span>)</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Min pixel value '</span>, new_img_arr.<span class="bu">min</span>()) </span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Max pixel value '</span>, new_img_arr.<span class="bu">max</span>())</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean pixel value '</span>, new_img_arr.mean().<span class="bu">round</span>())</span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a><span class="co"># normalize the RGB values to be between 0 and 1</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>new_img_arr_norm <span class="op">=</span> new_img_arr <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a><span class="co"># extract the min, max, and mean pixel values AFTER</span></span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'AFTER normalization'</span>) </span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Min pixel value '</span>, new_img_arr_norm.<span class="bu">min</span>()) </span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Max pixel value '</span>, new_img_arr_norm.<span class="bu">max</span>())</span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean pixel value '</span>, new_img_arr_norm.mean().<span class="bu">round</span>())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>BEFORE normalization
Min pixel value  0.0
Max pixel value  255.0
Mean pixel value  87.0
AFTER normalization
Min pixel value  0.0
Max pixel value  1.0
Mean pixel value  0.0</code></pre>
</div>
<div id="accordionSpoiler3" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler3" aria-expanded="false" aria-controls="collapseSpoiler3">
  <h3 class="accordion-header" id="headingSpoiler3">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>WANT TO KNOW MORE: Why Normalize?</h3>
</button>
<div id="collapseSpoiler3" class="accordion-collapse collapse" aria-labelledby="headingSpoiler3" data-bs-parent="#accordionSpoiler3">
<div class="accordion-body">
<p>ChatGPT</p>
<p>Normalizing the RGB values to be between 0 and 1 is a common
pre-processing step in machine learning tasks, especially when dealing
with image data. This normalization has several benefits:</p>
<ol style="list-style-type: decimal"><li><p><strong>Numerical Stability</strong>: By scaling the RGB values
to a range between 0 and 1, you avoid potential numerical instability
issues that can arise when working with large values. Neural networks
and many other machine learning algorithms are sensitive to the scale of
input features, and normalizing helps to keep the values within a
manageable range.</p></li>
<li><p><strong>Faster Convergence</strong>: Normalizing the RGB values
often helps in faster convergence during the training process. Neural
networks and other optimization algorithms rely on gradient descent
techniques, and having inputs in a consistent range aids in smoother and
faster convergence.</p></li>
<li><p><strong>Equal Weightage for All Channels</strong>: In RGB images,
each channel (Red, Green, Blue) represents different colour intensities.
By normalizing to the range [0, 1], you ensure that each channel is
treated with equal weightage during training. This is important because
some machine learning algorithms could assign more importance to larger
values.</p></li>
<li><p><strong>Generalization</strong>: Normalization helps the model to
generalize better to unseen data. When the input features are in the
same range, the learned weights and biases can be more effectively
applied to new examples, making the model more robust.</p></li>
<li><p><strong>Compatibility</strong>: Many image-related libraries,
algorithms, and models expect pixel values to be in the range of [0, 1].
By normalizing the RGB values, you ensure compatibility and seamless
integration with these tools.</p></li>
</ol><p>The normalization process is typically done by dividing each RGB
value (ranging from 0 to 255) by 255, which scales the values to the
range [0, 1].</p>
<p>For example, if you have an RGB image with pixel values (100, 150,
200), after normalization, the pixel values would become (100/255,
150/255, 200/255) ≈ (0.39, 0.59, 0.78).</p>
<p>Remember that normalization is not always mandatory, and there could
be cases where other scaling techniques might be more suitable based on
the specific problem and data distribution. However, for most
image-related tasks in machine learning, normalizing RGB values to [0,
1] is a good starting point.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="one-hot-encoding">One-hot encoding<a class="anchor" aria-label="anchor" href="#one-hot-encoding"></a></h3>
<p>A neural network can only take numerical inputs and outputs, and
learns by calculating how “far away” the class predicted by the neural
network is from the true class. When the target (label) is categorical
data, or strings, it is very difficult to determine this “distance” or
error. Therefore we will transform this column into a more suitable
format. There are many ways to do this, however we will be using
<strong>one-hot encoding</strong>.</p>
<p>One-hot encoding is a technique to represent categorical data as
binary vectors, making it compatible with machine learning algorithms.
Each category becomes a separate column, and the presence or absence of
a category is indicated by 1s and 0s in the respective columns.</p>
<p>Let’s say you have a dataset with a “colour” column containing three
categories: yellow, orange, purple.</p>
<p>Table 1. Original Data.</p>
<table class="table"><thead><tr class="header"><th>colour</th>
<th align="right"></th>
</tr></thead><tbody><tr class="odd"><td>yellow</td>
<td align="right"><span class="emoji" data-emoji="yellow_square">🟨</span></td>
</tr><tr class="even"><td>orange</td>
<td align="right"><span class="emoji" data-emoji="orange_square">🟧</span></td>
</tr><tr class="odd"><td>purple</td>
<td align="right"><span class="emoji" data-emoji="purple_square">🟪</span></td>
</tr><tr class="even"><td>yellow</td>
<td align="right"><span class="emoji" data-emoji="yellow_square">🟨</span></td>
</tr></tbody></table><p>Table 2. After One-Hot Encoding.</p>
<table class="table"><thead><tr class="header"><th>colour_yellow</th>
<th align="center">colour_orange</th>
<th align="right">colour_purple</th>
</tr></thead><tbody><tr class="odd"><td>1</td>
<td align="center">0</td>
<td align="right">0</td>
</tr><tr class="even"><td>0</td>
<td align="center">1</td>
<td align="right">0</td>
</tr><tr class="odd"><td>0</td>
<td align="center">0</td>
<td align="right">1</td>
</tr><tr class="even"><td>1</td>
<td align="center">0</td>
<td align="right">0</td>
</tr></tbody></table><p>The Keras function for one_hot encoding is called <a href="https://keras.io/api/utils/python_utils/#to_categorical-function" class="external-link">to_categorical</a>:</p>
<p><code>tf.keras.utils.to_categorical(y, num_classes=None, dtype="float32")</code></p>
<ul><li>
<code>y</code> is an array of class values to be converted into a
matrix (integers from 0 to num_classes - 1).</li>
<li>
<code>num_classes</code> is the total number of classes. If None,
this would be inferred as max(y) + 1.</li>
<li>
<code>dtype</code> is the data type expected by the input. Default:
‘float32’</li>
</ul></div>
<div class="section level3">
<h3 id="data-splitting">Data Splitting<a class="anchor" aria-label="anchor" href="#data-splitting"></a></h3>
<p>The typical practice in machine learning is to split your data into
two subsets: a <strong>training</strong> set and a <strong>test</strong>
set. This initial split separates the data you will use to train your
model from the data you will use to evaluate its performance.</p>
<p>After this initial split, you can choose to further split the
training set into a training set and a <strong>validation set</strong>.
This is often done when you are fine-tuning hyperparameters, selecting
the best model from a set of candidate models, or preventing
overfitting.</p>
<p>To split a dataset into training and test sets there is a very
convenient function from sklearn called <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" class="external-link">train_test_split</a>:</p>
<p><code>sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)</code></p>
<ul><li>The first two parameters are the dataset (X) and the corresponding
targets (y) (i.e. class labels).</li>
<li>Next is the named parameter <code>test_size</code>. This is the
fraction of the dataset used for testing and in this case
<code>0.2</code> means 20 per cent of the data will be used for
testing.</li>
<li>
<code>random_state</code> controls the shuffling of the dataset,
setting this value will reproduce the same results (assuming you give
the same integer) every time it is called.</li>
<li>
<code>shuffle</code> which can be either <code>True</code> or
<code>False</code>, it controls whether the order of the rows of the
dataset is shuffled before splitting. It defaults to
<code>True</code>.</li>
<li>
<code>stratify</code> is a more advanced parameter that controls how
the split is done. By setting it to <code>target</code> the train and
test sets the function will return will have roughly the same
proportions (with regards to the number of images of a certain class) as
the dataset.</li>
</ul></div>
</section><section id="pre-existing-image-data"><h2 class="section-heading">Pre-existing image data<a class="anchor" aria-label="anchor" href="#pre-existing-image-data"></a>
</h2>
<hr class="half-width"><p>In other cases you will be able to download an image dataset that is
already labelled and can be used to classify a number of different
object like the <a href="https://www.cs.toronto.edu/~kriz/cifar.html" class="external-link">CIFAR-10</a> dataset.
Other examples include:</p>
<ul><li>
<a href="https://en.wikipedia.org/wiki/MNIST_database" class="external-link">MNIST
database</a> - 60,000 training images of handwritten digits (0-9)</li>
<li>
<a href="https://www.image-net.org/" class="external-link">ImageNet</a> - 14 million
hand-annotated images indicating objects from more than 20,000
categories. ImageNet sponsors an <a href="https://www.image-net.org/challenges/LSVRC/#:~:text=The%20ImageNet%20Large%20Scale%20Visual,image%20classification%20at%20large%20scale." class="external-link">annual
software contest</a> where programs compete to achieve the highest
accuracy. When choosing a pretrained network, the winners of these sorts
of competitions are generally a good place to start.</li>
<li>
<a href="https://cocodataset.org/#home" class="external-link">MS COCO</a> - &gt;200,000
labelled images used for object detection, instance segmentation,
keypoint analysis, and captioning</li>
</ul><p>Where labelled data exists, in most cases the data provider or other
users will have created data-specific functions you can use to load the
data. We already did this in the introduction:</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="co"># load the CIFAR-10 dataset included with the keras library</span></span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>(train_images, train_labels), (test_images, test_labels) <span class="op">=</span> keras.datasets.cifar10.load_data()</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a><span class="co"># create a list of classnames associated with each CIFAR-10 label</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'airplane'</span>, <span class="st">'automobile'</span>, <span class="st">'bird'</span>, <span class="st">'cat'</span>, <span class="st">'deer'</span>, <span class="st">'dog'</span>, <span class="st">'frog'</span>, <span class="st">'horse'</span>, <span class="st">'ship'</span>, <span class="st">'truck'</span>]</span></code></pre>
</div>
<p>In this instance the data is likely already prepared for use in a
CNN. However, it is always a good idea to first read any associated
documentation to find out what steps the data providers took to prepare
the images and second to take a closer at the images once loaded and
query their attributes.</p>
<p>In our case, we still want prepare the datset with these steps:</p>
<ul><li>normalise the image pixel values to be between 0 and 1</li>
<li>one-hot encode the training image labels</li>
<li>divide the data into <strong>training</strong>,
<strong>validation</strong>, and <strong>test</strong> subsets</li>
</ul><p>We performed these operations in <strong>Step 3. Prepare
data</strong> of the Introduction but let us create the function to
prepare the dataset again knowing what we know now.</p>
<div id="challenge-create-a-function-to-prepare-the-dataset" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-create-a-function-to-prepare-the-dataset" class="callout-inner">
<h3 class="callout-title">CHALLENGE Create a function to prepare the
dataset<a class="anchor" aria-label="anchor" href="#challenge-create-a-function-to-prepare-the-dataset"></a>
</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="co"># create a function to prepare the dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="kw">def</span> prepare_dataset(<span class="co">#blank#, #blank#):</span></span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>    </span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>    <span class="co"># normalize the RGB values to be between 0 and 1</span></span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>    <span class="co">#blank#</span></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>    <span class="co">#blank#</span></span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a>    </span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a>    <span class="co"># one hot encode the training labels</span></span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a>    <span class="co">#blank#</span></span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a>    </span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a>    <span class="co"># split the training data into training and validation set</span></span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a>    <span class="co">#blank#</span></span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a>    <span class="co">#blank#</span></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a>    <span class="cf">return</span> <span class="co">#blank#</span></span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4">Show me the solution</h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="kw">def</span> prepare_dataset(train_images, train_labels):</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>    </span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>    <span class="co"># normalize the RGB values to be between 0 and 1</span></span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>    train_images <span class="op">=</span> train_images <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>    test_images <span class="op">=</span> train_labels <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>    </span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a>    <span class="co"># one hot encode the training labels</span></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>    train_labels <span class="op">=</span> keras.utils.to_categorical(train_labels, <span class="bu">len</span>(class_names))</span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a>    </span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>    <span class="co"># split the training data into training and validation set</span></span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a>    train_images, val_images, train_labels, val_labels <span class="op">=</span> train_test_split(</span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a>    train_images, train_labels, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a>    <span class="cf">return</span> train_images, val_images, train_labels, val_labels</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Inspect the labels before and after one-hot encoding.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train_labels before one hot encoding'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a><span class="bu">print</span>(train_labels)</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a><span class="co"># one-hot encode labels</span></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>train_labels <span class="op">=</span> keras.utils.to_categorical(train_labels, <span class="bu">len</span>(class_names))</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train_labels after one hot encoding'</span>)</span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a><span class="bu">print</span>(train_labels)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>train_labels before one hot encoding
[[6]
 [9]
 [9]
 ...
 [9]
 [1]
 [1]]

train_labels after one hot encoding
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 0. 0. 1.]
 ...
 [0. 0. 0. ... 0. 0. 1.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]]</code></pre>
</div>
<div id="callout3" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout3"></a>
</h3>
<div class="callout-content">
<p>WAIT I thought there were TEN classes!? Where is the rest of the
data?</p>
<p>The Spyder IDE uses the ‘…’ notation when it “hides” some of the data
for display purposes.</p>
<p>To view the entire array, go the Variable Explorer in the upper right
hand corner of your Spyder IDE and double click on the ‘train_labels’
object. This will open a new window that shows all of the columns.</p>
<figure><img src="fig/02_spyder_onehot_train_labels_inFULL.png" alt="Screenshot of Spyder window displaying the entire train_labels array." class="figure mx-auto d-block"></figure></div>
</div>
</div>
<div id="challenge-training-and-validation" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-training-and-validation" class="callout-inner">
<h3 class="callout-title">CHALLENGE Training and Validation<a class="anchor" aria-label="anchor" href="#challenge-training-and-validation"></a>
</h3>
<div class="callout-content">
<p>Inspect the training and validation sets we created.</p>
<p>How many samples does each set have and are the classes well
balanced?</p>
<p>Hint: Use <code>np.sum()</code> on the ’*_labels’ to find out if the
classes are well balanced.</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5">Show me the solution</h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>A. Training Set</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of training set images'</span>, train_images.shape[<span class="dv">0</span>])</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of images in each class:</span><span class="ch">\n</span><span class="st">'</span>, train_labels.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Number of training set images: 40000
Number of images in each class:
 [4027. 4021. 3970. 3977. 4067. 3985. 4004. 4006. 3983. 3960.]</code></pre>
</div>
<p>B. Validation Set (we can use the same code as the training set)</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of validation set images'</span>, val_images.shape[<span class="dv">0</span>])</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Nmber of images in each class:</span><span class="ch">\n</span><span class="st">'</span>, val_labels.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Number of validation set images: 10000
Nmber of images in each class:
 [ 973.  979. 1030. 1023.  933. 1015.  996.  994. 1017. 1040.]</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSpoiler4" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler4" aria-expanded="false" aria-controls="collapseSpoiler4">
  <h3 class="accordion-header" id="headingSpoiler4">
<div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>WANT TO KNOW MORE: Data Splitting Techniques</h3>
</button>
<div id="collapseSpoiler4" class="accordion-collapse collapse" aria-labelledby="headingSpoiler4" data-bs-parent="#accordionSpoiler4">
<div class="accordion-body">
<p>ChatGPT</p>
<p>Data is typically split into the training, validation, and test data
sets using a process called data splitting or data partitioning. There
are various methods to perform this split, and the choice of technique
depends on the specific problem, dataset size, and the nature of the
data. Here are some common approaches:</p>
<p><strong>Hold-Out Method:</strong></p>
<ul><li><p>In the hold-out method, the dataset is divided into two parts
initially: a training set and a test set.</p></li>
<li><p>The training set is used to train the model, and the test set is
kept completely separate to evaluate the model’s final
performance.</p></li>
<li><p>This method is straightforward and widely used when the dataset
is sufficiently large.</p></li>
</ul><p><strong>Train-Validation-Test Split:</strong></p>
<ul><li><p>The dataset is split into three parts: the training set, the
validation set, and the test set.</p></li>
<li><p>The training set is used to train the model, the validation set
is used to tune hyperparameters and prevent overfitting during training,
and the test set is used to assess the final model performance.</p></li>
<li><p>This method is commonly used when fine-tuning model
hyperparameters is necessary.</p></li>
</ul><p><strong>K-Fold Cross-Validation:</strong></p>
<ul><li><p>In k-fold cross-validation, the dataset is divided into k subsets
(folds) of roughly equal size.</p></li>
<li><p>The model is trained and evaluated k times, each time using a
different fold as the test set while the remaining k-1 folds are used as
the training set.</p></li>
<li><p>The final performance metric is calculated as the average of the
k evaluation results, providing a more robust estimate of model
performance.</p></li>
<li><p>This method is particularly useful when the dataset size is
limited, and it helps in better utilizing available data.</p></li>
</ul><p><strong>Stratified Sampling:</strong></p>
<ul><li><p>Stratified sampling is used when the dataset is imbalanced,
meaning some classes or categories are underrepresented.</p></li>
<li><p>The data is split in such a way that each subset (training,
validation, or test) maintains the same class distribution as the
original dataset.</p></li>
<li><p>This ensures all classes are well-represented in each subset,
which is important to avoid biased model evaluation.</p></li>
</ul><p>It’s important to note that the exact split ratios (e.g., 80-10-10 or
70-15-15) may vary depending on the problem, dataset size, and specific
requirements. Additionally, data splitting should be performed randomly
to avoid introducing any biases into the model training and evaluation
process.</p>
</div>
</div>
</div>
</div>
</section><section id="data-preprocessing-completed"><h2 class="section-heading">Data preprocessing completed!<a class="anchor" aria-label="anchor" href="#data-preprocessing-completed"></a>
</h2>
<hr class="half-width"><p>We now have a function we can use throughout the lesson to preprocess
our data which means we are ready to learn how to build a CNN like we
used in the introduction.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>Image datasets can be found online or created uniquely for your
research question.</li>
<li>Images consist of pixels arranged in a particular order.</li>
<li>Image data is usually preprocessed before use in a CNN for
efficiency, consistency, and robustness.</li>
<li>Input data generally consists of three sets: a training set used to
fit model parameters; a validation set used to evaluate the model fit on
training data; a test set used to evaluate the final model
performance.</li>
</ul></div>
</div>
</div>
<!-- Collect your link references at the bottom of your document -->
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="01-introduction.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="03-text-analysis.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="01-introduction.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Introduction to
        </a>
        <a class="chapter-link float-end" href="03-text-analysis.html" rel="next">
          Next: Text Analysis... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/edit/main/episodes/02-text-preprocessing.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qcif-training/intro_nlp_lmm_v1.0/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:training@qcif.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.4" class="external-link">sandpaper (0.16.4)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.5" class="external-link">pegboard (0.7.5)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.2" class="external-link">varnish (1.0.2)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/02-text-preprocessing.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Introduction to Text Preprocessing",
  "creativeWorkStatus": "active",
  "url": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/02-text-preprocessing.html",
  "identifier": "https://qcif-training.github.io/intro_nlp_lmm_v1.0/02-text-preprocessing.html",
  "dateCreated": "2024-05-10",
  "dateModified": "2024-05-12",
  "datePublished": "2024-05-12"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

